{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b096a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([492, 128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Get the pretrained weights and biases for when the model is pretrianed given 12 second long EEGs and distance based adjacencies\n",
    "model_pre = torch.load('pretrained_distance_graph_12s.pth.tar')\n",
    "\n",
    "# Convert dict_values to list\n",
    "state_dict_list = list(model_pre.values())\n",
    "\n",
    "# Now, the first element is an OrderedDict\n",
    "first_ordered_dict = state_dict_list[0]\n",
    "\n",
    "# Extract its items (key, tensor)\n",
    "first_items = list(first_ordered_dict.items())\n",
    "\n",
    "# Get the first tensor\n",
    "first_tensor = first_items[0][1]\n",
    "\n",
    "# Print the shape\n",
    "print(first_tensor.shape)\n",
    "\n",
    "# Get the first tensor\n",
    "second_tensor = first_items[1][1]\n",
    "\n",
    "# Print the shape\n",
    "print(second_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5499440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import os\n",
    "import mne\n",
    "import pickle\n",
    "\n",
    "# Specify the folder path containing the EDF files\n",
    "folder_path = 'C:/Users/Atena/Documents/edf_files'\n",
    "# Specify the folder path containing the CSV files\n",
    "folder_path_csv = 'C:/Users/Atena/Documents/csv_files'\n",
    "\n",
    "# Constants\n",
    "num_channels = 19\n",
    "epoch_length = 1  # in seconds\n",
    "electrodes = ['FP1', 'FP2', 'F7', 'F3', 'FZ', 'F4', 'F8', 'T3', 'C3', 'CZ', 'C4', 'T4', 'T5', 'P3', 'PZ', 'P4', 'T6', 'O1', 'O2']\n",
    "electrode_locations = {\n",
    "    'FP1': (-0.3, 0.8),\n",
    "    'FP2': (0.3, 0.8),\n",
    "    'F7': (-0.7, 0.5),\n",
    "    'F3': (-0.4, 0.4),\n",
    "    'FZ': (0.0, 0.3),\n",
    "    'F4': (0.4, 0.4),\n",
    "    'F8': (0.7, 0.5),\n",
    "    'T3': (-0.8, 0),\n",
    "    'C3': (-0.5, 0.0),\n",
    "    'CZ': (0.0, 0.0),\n",
    "    'C4': (0.5, 0.0),\n",
    "    'T4': (0.8, 0),\n",
    "    'T5': (-0.6, -0.5),\n",
    "    'P3': (-0.4, -0.4),\n",
    "    'PZ': (0.0, -0.3),\n",
    "    'P4': (0.4, -0.4),\n",
    "    'T6': (0.6, -0.5),\n",
    "    'O1': (-0.3, -0.8),\n",
    "    'O2': (0.3, -0.8)\n",
    "    }\n",
    "# Define the Butterworth filter parameters with filtfilt applied\n",
    "iir_params = dict(order=6, ftype='butter', output='sos')\n",
    "\n",
    "from scipy.signal import hilbert, butter, filtfilt\n",
    "def bandpass_filter(data, sfreq, low_freq, high_freq):\n",
    "    \"\"\"\n",
    "    Band-pass filter the data.\n",
    "    \n",
    "    Parameters:\n",
    "    data (ndarray): The input signal of shape (n_channels, n_times)\n",
    "    sfreq (float): The sampling frequency\n",
    "    low_freq (float): The lower bound of the frequency range\n",
    "    high_freq (float): The upper bound of the frequency range\n",
    "    \n",
    "    Returns:\n",
    "    filtered_data (ndarray): The band-pass filtered signal\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * sfreq\n",
    "    low = low_freq / nyquist\n",
    "    high = high_freq / nyquist\n",
    "    b, a = butter(4, [low, high], btype='band')\n",
    "    filtered_data = filtfilt(b, a, data, axis=1)\n",
    "    return filtered_data\n",
    "\n",
    "def epoch_data(data, sfreq, epoch_length):\n",
    "    n_channels, n_samples = data.shape\n",
    "    epoch_samples = int(epoch_length * sfreq)\n",
    "    n_epochs = n_samples // epoch_samples\n",
    "    epochs = np.array_split(data[:, :n_epochs * epoch_samples], n_epochs, axis=1)\n",
    "    return epochs, n_epochs\n",
    "\n",
    "def extract_sz_channels(file_path, sztype):\n",
    "    \"\"\"\n",
    "    Extract channel names corresponding to rows with the label '--sz' for each start and stop time,\n",
    "    merging times that are 5 seconds or less apart into the earliest time for start and largest for stop.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are tuples of (merged_start_time, merged_stop_time)\n",
    "              and values are lists of channel names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load CSV data, skipping lines that start with '#'\n",
    "        data = pd.read_csv(file_path, comment='#')\n",
    "\n",
    "        # Filter rows with the label 'sz'\n",
    "        sz_data = data[data['label'] == sztype]\n",
    "\n",
    "        # Sort and merge start times if they are within 1800 seconds\n",
    "        sorted_start_times = sorted(sz_data['start_time'].unique())\n",
    "        merged_start_times = []\n",
    "        current_group = [sorted_start_times[0]]\n",
    "\n",
    "        for i in range(1, len(sorted_start_times)):\n",
    "            if sorted_start_times[i] - current_group[-1] <= 10:\n",
    "                current_group.append(sorted_start_times[i])\n",
    "            else:\n",
    "                merged_start_times.append(current_group)\n",
    "                current_group = [sorted_start_times[i]]\n",
    "        merged_start_times.append(current_group)  # Add the last group\n",
    "\n",
    "        start_time_mapping = {\n",
    "            time: group[0] for group in merged_start_times for time in group\n",
    "        }\n",
    "\n",
    "        # Map each start time to the merged start time\n",
    "        sz_data['merged_start_time'] = sz_data['start_time'].map(start_time_mapping)\n",
    "\n",
    "        # Sort and merge stop times if they are within 1800 seconds\n",
    "        sorted_stop_times = sorted(sz_data['stop_time'].unique())\n",
    "        merged_stop_times = []\n",
    "        current_group = [sorted_stop_times[0]]\n",
    "\n",
    "        for i in range(1, len(sorted_stop_times)):\n",
    "            if sorted_stop_times[i] - current_group[-1] <= 10:\n",
    "                current_group.append(sorted_stop_times[i])\n",
    "            else:\n",
    "                merged_stop_times.append(current_group)\n",
    "                current_group = [sorted_stop_times[i]]\n",
    "        merged_stop_times.append(current_group)  # Add the last group\n",
    "\n",
    "        stop_time_mapping = {\n",
    "            time: group[-1] for group in merged_stop_times for time in group\n",
    "        }\n",
    "\n",
    "        # Map each stop time to the merged stop time\n",
    "        sz_data['merged_stop_time'] = sz_data['stop_time'].map(stop_time_mapping)\n",
    "\n",
    "        channelslist = list(sz_data['channel'])\n",
    "\n",
    "        from collections import Counter\n",
    "        nested_list = [channels.split('-') for channels in channelslist]\n",
    "        flat_list = [item for sublist in nested_list for item in sublist]\n",
    "        count_dict = Counter(flat_list)\n",
    "        foz_channels = [key for key, value in count_dict.items() if value >= 2]\n",
    "\n",
    "        focal_zone_channels = {(list(sz_data['merged_start_time'])[0], list(sz_data['merged_stop_time'])[0]): foz_channels}\n",
    "\n",
    "        return focal_zone_channels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file '{file_path}': {e}\")\n",
    "        return {}\n",
    "    \n",
    "n_segments = 12\n",
    "n_channels = 19\n",
    "n_freqs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188eea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_fft_features(eeg_array, n_freqs=100, epsilon=1e-6):\n",
    "    \"\"\"Compute log FFT amplitude features for a [19 Ã— 250] EEG segment.\"\"\"\n",
    "    n_channels, n_samples = eeg_array.shape\n",
    "    \n",
    "    fft_features = np.zeros((n_channels, n_freqs))\n",
    "    for ch in range(n_channels):\n",
    "        fft_result = np.fft.rfft(eeg_array[ch])\n",
    "        fft_amp = np.abs(fft_result)\n",
    "        fft_features[ch] = np.log(fft_amp[:n_freqs] + epsilon)\n",
    "    \n",
    "    return fft_features  # shape: (19, 100)\n",
    "\n",
    "n_segments = 12\n",
    "n_channels = 19\n",
    "n_freqs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ee7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eegsf = []\n",
    "# seizure_types = ['fnsz']\n",
    "\n",
    "# # Load the saved data\n",
    "# with open('FNSZ1.pkl', \"rb\") as f: \n",
    "#     loaded_data = pickle.load(f)\n",
    "# csv_file_names = loaded_data \n",
    "\n",
    "# for file_num in range(0, len(csv_file_names)):\n",
    "#     print(file_num)\n",
    "        \n",
    "#     csv_file_name = csv_file_names[file_num]\n",
    "#     csv_file_path = os.path.join(folder_path_csv, csv_file_name)\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_file_path, comment='#') \n",
    "\n",
    "#     # Extract the unique labels from the 'label' column, ignoring case sensitivity\n",
    "#     unique_labels = df['label'].str.lower().unique()\n",
    "#     FOZ = {}\n",
    "#     for sztype in seizure_types:\n",
    "#         sznum = seizure_types.index(sztype)\n",
    "        \n",
    "#         # Find matching labels (case-insensitive comparison)\n",
    "#         matching_labels = [label for label in unique_labels if label==sztype]\n",
    "\n",
    "#         # Convert the label column to lowercase for case-insensitive matching\n",
    "#         df['label'] = df['label'].str.lower()\n",
    "\n",
    "#         # Filter the rows that match the target labels\n",
    "#         matching_df = df[df['label']==sztype]\n",
    "\n",
    "#         # Check if any label contains 'sz'\n",
    "#         if any(sztype in label for label in unique_labels):\n",
    "#             channels = extract_sz_channels(csv_file_path, sztype)\n",
    "#             # Create a modified dictionary based on the logic\n",
    "#             channels_presence = {szt: np.array([1 if electrode in chans else 0 for electrode in electrodes]).T for szt, chans in channels.items()}\n",
    "\n",
    "#             FOZ = channels_presence\n",
    "\n",
    "#     seiz_start = list(FOZ.keys())[0][0]\n",
    "#     seiz_stop = list(FOZ.keys())[0][1]\n",
    "#     # Strip the .edf extension and look for the corresponding .csv file\n",
    "#     base_name = os.path.splitext(csv_file_name)[0]\n",
    "            \n",
    "#     edf_file_name = base_name + '.edf'\n",
    "#     file_path = os.path.join(folder_path, edf_file_name)\n",
    "        \n",
    "#     # Read the EDF file\n",
    "#     raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "#     dat, times = raw[:]\n",
    "#     sfreq = int(raw.info['sfreq'])\n",
    "#     if seiz_stop-seiz_start>12:\n",
    "#         data = dat[:, int(round((seiz_start)*sfreq)):int(round((seiz_start+12)*sfreq))]\n",
    "#         chs = raw.ch_names\n",
    "#         # Extract the info from the original raw object to preserve metadata\n",
    "#         info = raw.info\n",
    "\n",
    "#         modified_raw = mne.io.RawArray(data, info)\n",
    "\n",
    "#         # Define channel selection and renaming\n",
    "#         if any('REF' in ch for ch in chs):\n",
    "#             ref_suffix = '-REF'\n",
    "#         else:\n",
    "#             ref_suffix = '-LE'\n",
    "\n",
    "#         selected_channels = [\n",
    "#             f'EEG FP1{ref_suffix}', f'EEG FP2{ref_suffix}', f'EEG F7{ref_suffix}', f'EEG F3{ref_suffix}',\n",
    "#             f'EEG FZ{ref_suffix}', f'EEG F4{ref_suffix}', f'EEG F8{ref_suffix}', f'EEG T3{ref_suffix}',\n",
    "#             f'EEG C3{ref_suffix}', f'EEG CZ{ref_suffix}', f'EEG C4{ref_suffix}', f'EEG T4{ref_suffix}',\n",
    "#             f'EEG T5{ref_suffix}', f'EEG P3{ref_suffix}', f'EEG PZ{ref_suffix}', f'EEG P4{ref_suffix}',\n",
    "#             f'EEG T6{ref_suffix}', f'EEG O1{ref_suffix}', f'EEG O2{ref_suffix}'\n",
    "#         ]\n",
    "\n",
    "#         rename_dict = {ch: ch.replace(f'EEG ', '').replace(ref_suffix, '') for ch in selected_channels}\n",
    "\n",
    "#         raw_selected = modified_raw.copy()\n",
    "        \n",
    "#         # Get the list of available channels\n",
    "#         available_channels = raw_selected.info[\"ch_names\"]\n",
    "\n",
    "#         # Find missing channels\n",
    "#         missing_channels = [ch for ch in selected_channels if ch not in available_channels]\n",
    "\n",
    "#         # Raise an error or handle missing channels\n",
    "#         if missing_channels==[]:\n",
    "#             # Select the specified channels\n",
    "#             raw_selected = raw_selected.pick_channels(selected_channels)\n",
    "\n",
    "#             # Apply renaming\n",
    "#             raw_selected.rename_channels(rename_dict)\n",
    "\n",
    "#             # Filter the data\n",
    "#             preprocEEG = raw_selected.copy()\n",
    "#             # Band-pass filter the data using a 6th-order Butterworth filter with filtfilt applied\n",
    "#             preprocEEG.filter(l_freq=1.0, h_freq=40, method='iir', iir_params=iir_params, phase='zero')\n",
    "#             # Notch filter to remove power line noise (assuming 60 Hz)\n",
    "#             preprocEEG.notch_filter(freqs=60.0)\n",
    "\n",
    "#             eegICA = preprocEEG\n",
    "\n",
    "#             eegICA.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "#             eeg_data, times = eegICA[:]\n",
    "#             eeg_epochs, n_epochs = epoch_data(eeg_data, sfreq, epoch_length)\n",
    "\n",
    "#             features = np.zeros((n_segments, n_channels, n_freqs))\n",
    "#             for g, segment in enumerate(eeg_epochs):\n",
    "#                 features[g] = compute_log_fft_features(segment)\n",
    "\n",
    "#             eegsf.append(features)\n",
    "\n",
    "\n",
    "# eegsg = []\n",
    "# seizure_types = ['gnsz']\n",
    "\n",
    "# # Load the saved data\n",
    "# with open('GNSZ1.pkl', \"rb\") as f: \n",
    "#     loaded_data = pickle.load(f)\n",
    "# csv_file_names = loaded_data \n",
    "\n",
    "# for file_num in range(0, len(csv_file_names)):\n",
    "#     print(file_num)\n",
    "        \n",
    "#     csv_file_name = csv_file_names[file_num]\n",
    "#     csv_file_path = os.path.join(folder_path_csv, csv_file_name)\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_file_path, comment='#') \n",
    "\n",
    "#     # Extract the unique labels from the 'label' column, ignoring case sensitivity\n",
    "#     unique_labels = df['label'].str.lower().unique()\n",
    "#     FOZ = {}\n",
    "#     for sztype in seizure_types:\n",
    "#         sznum = seizure_types.index(sztype)\n",
    "        \n",
    "#         # Find matching labels (case-insensitive comparison)\n",
    "#         matching_labels = [label for label in unique_labels if label==sztype]\n",
    "\n",
    "#         # Convert the label column to lowercase for case-insensitive matching\n",
    "#         df['label'] = df['label'].str.lower()\n",
    "\n",
    "#         # Filter the rows that match the target labels\n",
    "#         matching_df = df[df['label']==sztype]\n",
    "\n",
    "#         # Check if any label contains 'sz'\n",
    "#         if any(sztype in label for label in unique_labels):\n",
    "#             channels = extract_sz_channels(csv_file_path, sztype)\n",
    "#             # Create a modified dictionary based on the logic\n",
    "#             channels_presence = {szt: np.array([1 if electrode in chans else 0 for electrode in electrodes]).T for szt, chans in channels.items()}\n",
    "\n",
    "#             FOZ = channels_presence\n",
    "\n",
    "#     seiz_start = list(FOZ.keys())[0][0]\n",
    "#     seiz_stop = list(FOZ.keys())[0][1]\n",
    "#     # Strip the .edf extension and look for the corresponding .csv file\n",
    "#     base_name = os.path.splitext(csv_file_name)[0]\n",
    "            \n",
    "#     edf_file_name = base_name + '.edf'\n",
    "#     file_path = os.path.join(folder_path, edf_file_name)\n",
    "        \n",
    "#     # Read the EDF file\n",
    "#     raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "#     dat, times = raw[:]\n",
    "#     sfreq = int(raw.info['sfreq'])\n",
    "#     if seiz_stop-seiz_start>12:\n",
    "#         data = dat[:, int(round((seiz_start)*sfreq)):int(round((seiz_start+12)*sfreq))]\n",
    "#         chs = raw.ch_names\n",
    "#         # Extract the info from the original raw object to preserve metadata\n",
    "#         info = raw.info\n",
    "\n",
    "#         modified_raw = mne.io.RawArray(data, info)\n",
    "\n",
    "#         # Define channel selection and renaming\n",
    "#         if any('REF' in ch for ch in chs):\n",
    "#             ref_suffix = '-REF'\n",
    "#         else:\n",
    "#             ref_suffix = '-LE'\n",
    "\n",
    "#         selected_channels = [\n",
    "#             f'EEG FP1{ref_suffix}', f'EEG FP2{ref_suffix}', f'EEG F7{ref_suffix}', f'EEG F3{ref_suffix}',\n",
    "#             f'EEG FZ{ref_suffix}', f'EEG F4{ref_suffix}', f'EEG F8{ref_suffix}', f'EEG T3{ref_suffix}',\n",
    "#             f'EEG C3{ref_suffix}', f'EEG CZ{ref_suffix}', f'EEG C4{ref_suffix}', f'EEG T4{ref_suffix}',\n",
    "#             f'EEG T5{ref_suffix}', f'EEG P3{ref_suffix}', f'EEG PZ{ref_suffix}', f'EEG P4{ref_suffix}',\n",
    "#             f'EEG T6{ref_suffix}', f'EEG O1{ref_suffix}', f'EEG O2{ref_suffix}'\n",
    "#         ]\n",
    "\n",
    "#         rename_dict = {ch: ch.replace(f'EEG ', '').replace(ref_suffix, '') for ch in selected_channels}\n",
    "\n",
    "#         raw_selected = modified_raw.copy()\n",
    "        \n",
    "#         # Get the list of available channels\n",
    "#         available_channels = raw_selected.info[\"ch_names\"]\n",
    "\n",
    "#         # Find missing channels\n",
    "#         missing_channels = [ch for ch in selected_channels if ch not in available_channels]\n",
    "\n",
    "#         # Raise an error or handle missing channels\n",
    "#         if missing_channels==[]:\n",
    "#             # Select the specified channels\n",
    "#             raw_selected = raw_selected.pick_channels(selected_channels)\n",
    "\n",
    "#             # Apply renaming\n",
    "#             raw_selected.rename_channels(rename_dict)\n",
    "\n",
    "#             # Filter the data\n",
    "#             preprocEEG = raw_selected.copy()\n",
    "#             # Band-pass filter the data using a 6th-order Butterworth filter with filtfilt applied\n",
    "#             preprocEEG.filter(l_freq=1.0, h_freq=40, method='iir', iir_params=iir_params, phase='zero')\n",
    "#             # Notch filter to remove power line noise (assuming 60 Hz)\n",
    "#             preprocEEG.notch_filter(freqs=60.0)\n",
    "\n",
    "#             eegICA = preprocEEG\n",
    "\n",
    "#             eegICA.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "#             eeg_data, times = eegICA[:]\n",
    "#             eeg_epochs, n_epochs = epoch_data(eeg_data, sfreq, epoch_length)\n",
    "\n",
    "#             features = np.zeros((n_segments, n_channels, n_freqs))\n",
    "#             for g, segment in enumerate(eeg_epochs):\n",
    "#                 features[g] = compute_log_fft_features(segment)\n",
    "\n",
    "#             eegsg.append(features)\n",
    "\n",
    "\n",
    "# eegscp = []\n",
    "# seizure_types = ['cpsz']\n",
    "\n",
    "# # Load the saved data\n",
    "# with open('CPSZ1.pkl', \"rb\") as f: \n",
    "#     loaded_data = pickle.load(f)\n",
    "# csv_file_names = loaded_data \n",
    "\n",
    "# for file_num in range(0, len(csv_file_names)):\n",
    "#     print(file_num)\n",
    "        \n",
    "#     csv_file_name = csv_file_names[file_num]\n",
    "#     csv_file_path = os.path.join(folder_path_csv, csv_file_name)\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_file_path, comment='#') \n",
    "\n",
    "#     # Extract the unique labels from the 'label' column, ignoring case sensitivity\n",
    "#     unique_labels = df['label'].str.lower().unique()\n",
    "#     FOZ = {}\n",
    "#     for sztype in seizure_types:\n",
    "#         sznum = seizure_types.index(sztype)\n",
    "        \n",
    "#         # Find matching labels (case-insensitive comparison)\n",
    "#         matching_labels = [label for label in unique_labels if label==sztype]\n",
    "\n",
    "#         # Convert the label column to lowercase for case-insensitive matching\n",
    "#         df['label'] = df['label'].str.lower()\n",
    "\n",
    "#         # Filter the rows that match the target labels\n",
    "#         matching_df = df[df['label']==sztype]\n",
    "\n",
    "#         # Check if any label contains 'sz'\n",
    "#         if any(sztype in label for label in unique_labels):\n",
    "#             channels = extract_sz_channels(csv_file_path, sztype)\n",
    "#             # Create a modified dictionary based on the logic\n",
    "#             channels_presence = {szt: np.array([1 if electrode in chans else 0 for electrode in electrodes]).T for szt, chans in channels.items()}\n",
    "\n",
    "#             FOZ = channels_presence\n",
    "\n",
    "#     seiz_start = list(FOZ.keys())[0][0]\n",
    "#     seiz_stop = list(FOZ.keys())[0][1]\n",
    "#     # Strip the .edf extension and look for the corresponding .csv file\n",
    "#     base_name = os.path.splitext(csv_file_name)[0]\n",
    "            \n",
    "#     edf_file_name = base_name + '.edf'\n",
    "#     file_path = os.path.join(folder_path, edf_file_name)\n",
    "        \n",
    "#     # Read the EDF file\n",
    "#     raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "#     dat, times = raw[:]\n",
    "#     sfreq = int(raw.info['sfreq'])\n",
    "#     if seiz_stop-seiz_start>12:\n",
    "#         data = dat[:, int(round((seiz_start)*sfreq)):int(round((seiz_start+12)*sfreq))]\n",
    "#         chs = raw.ch_names\n",
    "#         # Extract the info from the original raw object to preserve metadata\n",
    "#         info = raw.info\n",
    "\n",
    "#         modified_raw = mne.io.RawArray(data, info)\n",
    "\n",
    "#         # Define channel selection and renaming\n",
    "#         if any('REF' in ch for ch in chs):\n",
    "#             ref_suffix = '-REF'\n",
    "#         else:\n",
    "#             ref_suffix = '-LE'\n",
    "\n",
    "#         selected_channels = [\n",
    "#             f'EEG FP1{ref_suffix}', f'EEG FP2{ref_suffix}', f'EEG F7{ref_suffix}', f'EEG F3{ref_suffix}',\n",
    "#             f'EEG FZ{ref_suffix}', f'EEG F4{ref_suffix}', f'EEG F8{ref_suffix}', f'EEG T3{ref_suffix}',\n",
    "#             f'EEG C3{ref_suffix}', f'EEG CZ{ref_suffix}', f'EEG C4{ref_suffix}', f'EEG T4{ref_suffix}',\n",
    "#             f'EEG T5{ref_suffix}', f'EEG P3{ref_suffix}', f'EEG PZ{ref_suffix}', f'EEG P4{ref_suffix}',\n",
    "#             f'EEG T6{ref_suffix}', f'EEG O1{ref_suffix}', f'EEG O2{ref_suffix}'\n",
    "#         ]\n",
    "\n",
    "#         rename_dict = {ch: ch.replace(f'EEG ', '').replace(ref_suffix, '') for ch in selected_channels}\n",
    "\n",
    "#         raw_selected = modified_raw.copy()\n",
    "        \n",
    "#         # Get the list of available channels\n",
    "#         available_channels = raw_selected.info[\"ch_names\"]\n",
    "\n",
    "#         # Find missing channels\n",
    "#         missing_channels = [ch for ch in selected_channels if ch not in available_channels]\n",
    "\n",
    "#         # Raise an error or handle missing channels\n",
    "#         if missing_channels==[]:\n",
    "#             # Select the specified channels\n",
    "#             raw_selected = raw_selected.pick_channels(selected_channels)\n",
    "\n",
    "#             # Apply renaming\n",
    "#             raw_selected.rename_channels(rename_dict)\n",
    "\n",
    "#             # Filter the data\n",
    "#             preprocEEG = raw_selected.copy()\n",
    "#             # Band-pass filter the data using a 6th-order Butterworth filter with filtfilt applied\n",
    "#             preprocEEG.filter(l_freq=1.0, h_freq=40, method='iir', iir_params=iir_params, phase='zero')\n",
    "#             # Notch filter to remove power line noise (assuming 60 Hz)\n",
    "#             preprocEEG.notch_filter(freqs=60.0)\n",
    "\n",
    "#             eegICA = preprocEEG\n",
    "\n",
    "#             eegICA.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "#             eeg_data, times = eegICA[:]\n",
    "#             eeg_epochs, n_epochs = epoch_data(eeg_data, sfreq, epoch_length)\n",
    "\n",
    "#             features = np.zeros((n_segments, n_channels, n_freqs))\n",
    "#             for g, segment in enumerate(eeg_epochs):\n",
    "#                 features[g] = compute_log_fft_features(segment)\n",
    "\n",
    "#             eegscp.append(features)\n",
    "\n",
    "\n",
    "# eegsa = []\n",
    "# seizure_types = ['absz']\n",
    "\n",
    "# # Load the saved data\n",
    "# with open('ABSZ1.pkl', \"rb\") as f: \n",
    "#     loaded_data = pickle.load(f)\n",
    "# csv_file_names = loaded_data \n",
    "\n",
    "# for file_num in range(0, len(csv_file_names)):\n",
    "#     print(file_num)\n",
    "        \n",
    "#     csv_file_name = csv_file_names[file_num]\n",
    "#     csv_file_path = os.path.join(folder_path_csv, csv_file_name)\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_file_path, comment='#') \n",
    "\n",
    "#     # Extract the unique labels from the 'label' column, ignoring case sensitivity\n",
    "#     unique_labels = df['label'].str.lower().unique()\n",
    "#     FOZ = {}\n",
    "#     for sztype in seizure_types:\n",
    "#         sznum = seizure_types.index(sztype)\n",
    "        \n",
    "#         # Find matching labels (case-insensitive comparison)\n",
    "#         matching_labels = [label for label in unique_labels if label==sztype]\n",
    "\n",
    "#         # Convert the label column to lowercase for case-insensitive matching\n",
    "#         df['label'] = df['label'].str.lower()\n",
    "\n",
    "#         # Filter the rows that match the target labels\n",
    "#         matching_df = df[df['label']==sztype]\n",
    "\n",
    "#         # Check if any label contains 'sz'\n",
    "#         if any(sztype in label for label in unique_labels):\n",
    "#             channels = extract_sz_channels(csv_file_path, sztype)\n",
    "#             # Create a modified dictionary based on the logic\n",
    "#             channels_presence = {szt: np.array([1 if electrode in chans else 0 for electrode in electrodes]).T for szt, chans in channels.items()}\n",
    "\n",
    "#             FOZ = channels_presence\n",
    "\n",
    "#     seiz_start = list(FOZ.keys())[0][0]\n",
    "#     seiz_stop = list(FOZ.keys())[0][1]\n",
    "#     # Strip the .edf extension and look for the corresponding .csv file\n",
    "#     base_name = os.path.splitext(csv_file_name)[0]\n",
    "            \n",
    "#     edf_file_name = base_name + '.edf'\n",
    "#     file_path = os.path.join(folder_path, edf_file_name)\n",
    "        \n",
    "#     # Read the EDF file\n",
    "#     raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "#     dat, times = raw[:]\n",
    "#     sfreq = int(raw.info['sfreq'])\n",
    "#     if seiz_stop-seiz_start>12:\n",
    "#         data = dat[:, int(round((seiz_start)*sfreq)):int(round((seiz_start+12)*sfreq))]\n",
    "#         chs = raw.ch_names\n",
    "#         # Extract the info from the original raw object to preserve metadata\n",
    "#         info = raw.info\n",
    "\n",
    "#         modified_raw = mne.io.RawArray(data, info)\n",
    "\n",
    "#         # Define channel selection and renaming\n",
    "#         if any('REF' in ch for ch in chs):\n",
    "#             ref_suffix = '-REF'\n",
    "#         else:\n",
    "#             ref_suffix = '-LE'\n",
    "\n",
    "#         selected_channels = [\n",
    "#             f'EEG FP1{ref_suffix}', f'EEG FP2{ref_suffix}', f'EEG F7{ref_suffix}', f'EEG F3{ref_suffix}',\n",
    "#             f'EEG FZ{ref_suffix}', f'EEG F4{ref_suffix}', f'EEG F8{ref_suffix}', f'EEG T3{ref_suffix}',\n",
    "#             f'EEG C3{ref_suffix}', f'EEG CZ{ref_suffix}', f'EEG C4{ref_suffix}', f'EEG T4{ref_suffix}',\n",
    "#             f'EEG T5{ref_suffix}', f'EEG P3{ref_suffix}', f'EEG PZ{ref_suffix}', f'EEG P4{ref_suffix}',\n",
    "#             f'EEG T6{ref_suffix}', f'EEG O1{ref_suffix}', f'EEG O2{ref_suffix}'\n",
    "#         ]\n",
    "\n",
    "#         rename_dict = {ch: ch.replace(f'EEG ', '').replace(ref_suffix, '') for ch in selected_channels}\n",
    "\n",
    "#         raw_selected = modified_raw.copy()\n",
    "        \n",
    "#         # Get the list of available channels\n",
    "#         available_channels = raw_selected.info[\"ch_names\"]\n",
    "\n",
    "#         # Find missing channels\n",
    "#         missing_channels = [ch for ch in selected_channels if ch not in available_channels]\n",
    "\n",
    "#         # Raise an error or handle missing channels\n",
    "#         if missing_channels==[]:\n",
    "#             # Select the specified channels\n",
    "#             raw_selected = raw_selected.pick_channels(selected_channels)\n",
    "\n",
    "#             # Apply renaming\n",
    "#             raw_selected.rename_channels(rename_dict)\n",
    "\n",
    "#             # Filter the data\n",
    "#             preprocEEG = raw_selected.copy()\n",
    "#             # Band-pass filter the data using a 6th-order Butterworth filter with filtfilt applied\n",
    "#             preprocEEG.filter(l_freq=1.0, h_freq=40, method='iir', iir_params=iir_params, phase='zero')\n",
    "#             # Notch filter to remove power line noise (assuming 60 Hz)\n",
    "#             preprocEEG.notch_filter(freqs=60.0)\n",
    "\n",
    "#             eegICA = preprocEEG\n",
    "\n",
    "#             eegICA.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "#             eeg_data, times = eegICA[:]\n",
    "#             eeg_epochs, n_epochs = epoch_data(eeg_data, sfreq, epoch_length)\n",
    "\n",
    "#             features = np.zeros((n_segments, n_channels, n_freqs))\n",
    "#             for g, segment in enumerate(eeg_epochs):\n",
    "#                 features[g] = compute_log_fft_features(segment)\n",
    "\n",
    "#             eegsa.append(features)\n",
    "\n",
    "\n",
    "# eegstc = []\n",
    "# seizure_types = ['tcsz']\n",
    "\n",
    "# # Load the saved data\n",
    "# with open('TCSZ1.pkl', \"rb\") as f: \n",
    "#     loaded_data = pickle.load(f)\n",
    "# csv_file_names = loaded_data \n",
    "\n",
    "# for file_num in range(0, len(csv_file_names)):\n",
    "#     print(file_num)\n",
    "        \n",
    "#     csv_file_name = csv_file_names[file_num]\n",
    "#     csv_file_path = os.path.join(folder_path_csv, csv_file_name)\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_file_path, comment='#') \n",
    "\n",
    "#     # Extract the unique labels from the 'label' column, ignoring case sensitivity\n",
    "#     unique_labels = df['label'].str.lower().unique()\n",
    "#     FOZ = {}\n",
    "#     for sztype in seizure_types:\n",
    "#         sznum = seizure_types.index(sztype)\n",
    "        \n",
    "#         # Find matching labels (case-insensitive comparison)\n",
    "#         matching_labels = [label for label in unique_labels if label==sztype]\n",
    "\n",
    "#         # Convert the label column to lowercase for case-insensitive matching\n",
    "#         df['label'] = df['label'].str.lower()\n",
    "\n",
    "#         # Filter the rows that match the target labels\n",
    "#         matching_df = df[df['label']==sztype]\n",
    "\n",
    "#         # Check if any label contains 'sz'\n",
    "#         if any(sztype in label for label in unique_labels):\n",
    "#             channels = extract_sz_channels(csv_file_path, sztype)\n",
    "#             # Create a modified dictionary based on the logic\n",
    "#             channels_presence = {szt: np.array([1 if electrode in chans else 0 for electrode in electrodes]).T for szt, chans in channels.items()}\n",
    "\n",
    "#             FOZ = channels_presence\n",
    "\n",
    "#     seiz_start = list(FOZ.keys())[0][0]\n",
    "#     seiz_stop = list(FOZ.keys())[0][1]\n",
    "#     # Strip the .edf extension and look for the corresponding .csv file\n",
    "#     base_name = os.path.splitext(csv_file_name)[0]\n",
    "            \n",
    "#     edf_file_name = base_name + '.edf'\n",
    "#     file_path = os.path.join(folder_path, edf_file_name)\n",
    "        \n",
    "#     # Read the EDF file\n",
    "#     raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "#     dat, times = raw[:]\n",
    "#     sfreq = int(raw.info['sfreq'])\n",
    "#     if seiz_stop-seiz_start>12:\n",
    "#         data = dat[:, int(round((seiz_start)*sfreq)):int(round((seiz_start+12)*sfreq))]\n",
    "#         chs = raw.ch_names\n",
    "#         # Extract the info from the original raw object to preserve metadata\n",
    "#         info = raw.info\n",
    "\n",
    "#         modified_raw = mne.io.RawArray(data, info)\n",
    "\n",
    "#         # Define channel selection and renaming\n",
    "#         if any('REF' in ch for ch in chs):\n",
    "#             ref_suffix = '-REF'\n",
    "#         else:\n",
    "#             ref_suffix = '-LE'\n",
    "\n",
    "#         selected_channels = [\n",
    "#             f'EEG FP1{ref_suffix}', f'EEG FP2{ref_suffix}', f'EEG F7{ref_suffix}', f'EEG F3{ref_suffix}',\n",
    "#             f'EEG FZ{ref_suffix}', f'EEG F4{ref_suffix}', f'EEG F8{ref_suffix}', f'EEG T3{ref_suffix}',\n",
    "#             f'EEG C3{ref_suffix}', f'EEG CZ{ref_suffix}', f'EEG C4{ref_suffix}', f'EEG T4{ref_suffix}',\n",
    "#             f'EEG T5{ref_suffix}', f'EEG P3{ref_suffix}', f'EEG PZ{ref_suffix}', f'EEG P4{ref_suffix}',\n",
    "#             f'EEG T6{ref_suffix}', f'EEG O1{ref_suffix}', f'EEG O2{ref_suffix}'\n",
    "#         ]\n",
    "\n",
    "#         rename_dict = {ch: ch.replace(f'EEG ', '').replace(ref_suffix, '') for ch in selected_channels}\n",
    "\n",
    "#         raw_selected = modified_raw.copy()\n",
    "        \n",
    "#         # Get the list of available channels\n",
    "#         available_channels = raw_selected.info[\"ch_names\"]\n",
    "\n",
    "#         # Find missing channels\n",
    "#         missing_channels = [ch for ch in selected_channels if ch not in available_channels]\n",
    "\n",
    "#         # Raise an error or handle missing channels\n",
    "#         if missing_channels==[]:\n",
    "#             # Select the specified channels\n",
    "#             raw_selected = raw_selected.pick_channels(selected_channels)\n",
    "\n",
    "#             # Apply renaming\n",
    "#             raw_selected.rename_channels(rename_dict)\n",
    "\n",
    "#             # Filter the data\n",
    "#             preprocEEG = raw_selected.copy()\n",
    "#             # Band-pass filter the data using a 6th-order Butterworth filter with filtfilt applied\n",
    "#             preprocEEG.filter(l_freq=1.0, h_freq=40, method='iir', iir_params=iir_params, phase='zero')\n",
    "#             # Notch filter to remove power line noise (assuming 60 Hz)\n",
    "#             preprocEEG.notch_filter(freqs=60.0)\n",
    "\n",
    "#             eegICA = preprocEEG\n",
    "\n",
    "#             eegICA.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "#             eeg_data, times = eegICA[:]\n",
    "#             eeg_epochs, n_epochs = epoch_data(eeg_data, sfreq, epoch_length)\n",
    "\n",
    "#             features = np.zeros((n_segments, n_channels, n_freqs))\n",
    "#             for g, segment in enumerate(eeg_epochs):\n",
    "#                 features[g] = compute_log_fft_features(segment)\n",
    "\n",
    "#             eegstc.append(features)\n",
    "\n",
    "\n",
    "# eegst = []\n",
    "# seizure_types = ['tnsz']\n",
    "\n",
    "# # Load the saved data\n",
    "# with open('TNSZ1.pkl', \"rb\") as f: \n",
    "#     loaded_data = pickle.load(f)\n",
    "# csv_file_names = loaded_data \n",
    "\n",
    "# for file_num in range(0, len(csv_file_names)):\n",
    "#     print(file_num)\n",
    "        \n",
    "#     csv_file_name = csv_file_names[file_num]\n",
    "#     csv_file_path = os.path.join(folder_path_csv, csv_file_name)\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_file_path, comment='#') \n",
    "\n",
    "#     # Extract the unique labels from the 'label' column, ignoring case sensitivity\n",
    "#     unique_labels = df['label'].str.lower().unique()\n",
    "#     FOZ = {}\n",
    "#     for sztype in seizure_types:\n",
    "#         sznum = seizure_types.index(sztype)\n",
    "        \n",
    "#         # Find matching labels (case-insensitive comparison)\n",
    "#         matching_labels = [label for label in unique_labels if label==sztype]\n",
    "\n",
    "#         # Convert the label column to lowercase for case-insensitive matching\n",
    "#         df['label'] = df['label'].str.lower()\n",
    "\n",
    "#         # Filter the rows that match the target labels\n",
    "#         matching_df = df[df['label']==sztype]\n",
    "\n",
    "#         # Check if any label contains 'sz'\n",
    "#         if any(sztype in label for label in unique_labels):\n",
    "#             channels = extract_sz_channels(csv_file_path, sztype)\n",
    "#             # Create a modified dictionary based on the logic\n",
    "#             channels_presence = {szt: np.array([1 if electrode in chans else 0 for electrode in electrodes]).T for szt, chans in channels.items()}\n",
    "\n",
    "#             FOZ = channels_presence\n",
    "\n",
    "#     seiz_start = list(FOZ.keys())[0][0]\n",
    "#     seiz_stop = list(FOZ.keys())[0][1]\n",
    "#     # Strip the .edf extension and look for the corresponding .csv file\n",
    "#     base_name = os.path.splitext(csv_file_name)[0]\n",
    "            \n",
    "#     edf_file_name = base_name + '.edf'\n",
    "#     file_path = os.path.join(folder_path, edf_file_name)\n",
    "        \n",
    "#     # Read the EDF file\n",
    "#     raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "#     dat, times = raw[:]\n",
    "#     sfreq = int(raw.info['sfreq'])\n",
    "#     if seiz_stop-seiz_start>12:\n",
    "#         data = dat[:, int(round((seiz_start)*sfreq)):int(round((seiz_start+12)*sfreq))]\n",
    "#         chs = raw.ch_names\n",
    "#         # Extract the info from the original raw object to preserve metadata\n",
    "#         info = raw.info\n",
    "\n",
    "#         modified_raw = mne.io.RawArray(data, info)\n",
    "\n",
    "#         # Define channel selection and renaming\n",
    "#         if any('REF' in ch for ch in chs):\n",
    "#             ref_suffix = '-REF'\n",
    "#         else:\n",
    "#             ref_suffix = '-LE'\n",
    "\n",
    "#         selected_channels = [\n",
    "#             f'EEG FP1{ref_suffix}', f'EEG FP2{ref_suffix}', f'EEG F7{ref_suffix}', f'EEG F3{ref_suffix}',\n",
    "#             f'EEG FZ{ref_suffix}', f'EEG F4{ref_suffix}', f'EEG F8{ref_suffix}', f'EEG T3{ref_suffix}',\n",
    "#             f'EEG C3{ref_suffix}', f'EEG CZ{ref_suffix}', f'EEG C4{ref_suffix}', f'EEG T4{ref_suffix}',\n",
    "#             f'EEG T5{ref_suffix}', f'EEG P3{ref_suffix}', f'EEG PZ{ref_suffix}', f'EEG P4{ref_suffix}',\n",
    "#             f'EEG T6{ref_suffix}', f'EEG O1{ref_suffix}', f'EEG O2{ref_suffix}'\n",
    "#         ]\n",
    "\n",
    "#         rename_dict = {ch: ch.replace(f'EEG ', '').replace(ref_suffix, '') for ch in selected_channels}\n",
    "\n",
    "#         raw_selected = modified_raw.copy()\n",
    "        \n",
    "#         # Get the list of available channels\n",
    "#         available_channels = raw_selected.info[\"ch_names\"]\n",
    "\n",
    "#         # Find missing channels\n",
    "#         missing_channels = [ch for ch in selected_channels if ch not in available_channels]\n",
    "\n",
    "#         # Raise an error or handle missing channels\n",
    "#         if missing_channels==[]:\n",
    "#             # Select the specified channels\n",
    "#             raw_selected = raw_selected.pick_channels(selected_channels)\n",
    "\n",
    "#             # Apply renaming\n",
    "#             raw_selected.rename_channels(rename_dict)\n",
    "\n",
    "#             # Filter the data\n",
    "#             preprocEEG = raw_selected.copy()\n",
    "#             # Band-pass filter the data using a 6th-order Butterworth filter with filtfilt applied\n",
    "#             preprocEEG.filter(l_freq=1.0, h_freq=40, method='iir', iir_params=iir_params, phase='zero')\n",
    "#             # Notch filter to remove power line noise (assuming 60 Hz)\n",
    "#             preprocEEG.notch_filter(freqs=60.0)\n",
    "\n",
    "#             eegICA = preprocEEG\n",
    "\n",
    "#             eegICA.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "#             eeg_data, times = eegICA[:]\n",
    "#             eeg_epochs, n_epochs = epoch_data(eeg_data, sfreq, epoch_length)\n",
    "\n",
    "#             features = np.zeros((n_segments, n_channels, n_freqs))\n",
    "#             for g, segment in enumerate(eeg_epochs):\n",
    "#                 features[g] = compute_log_fft_features(segment)\n",
    "\n",
    "#             eegst.append(features)\n",
    "\n",
    "\n",
    "# eegssp = []\n",
    "# seizure_types = ['spsz']\n",
    "\n",
    "# # Load the saved data\n",
    "# with open('SPSZ1.pkl', \"rb\") as f: \n",
    "#     loaded_data = pickle.load(f)\n",
    "# csv_file_names = loaded_data \n",
    "\n",
    "# for file_num in range(0, len(csv_file_names)):\n",
    "#     print(file_num)\n",
    "        \n",
    "#     csv_file_name = csv_file_names[file_num]\n",
    "#     csv_file_path = os.path.join(folder_path_csv, csv_file_name)\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_file_path, comment='#') \n",
    "\n",
    "#     # Extract the unique labels from the 'label' column, ignoring case sensitivity\n",
    "#     unique_labels = df['label'].str.lower().unique()\n",
    "#     FOZ = {}\n",
    "#     for sztype in seizure_types:\n",
    "#         sznum = seizure_types.index(sztype)\n",
    "        \n",
    "#         # Find matching labels (case-insensitive comparison)\n",
    "#         matching_labels = [label for label in unique_labels if label==sztype]\n",
    "\n",
    "#         # Convert the label column to lowercase for case-insensitive matching\n",
    "#         df['label'] = df['label'].str.lower()\n",
    "\n",
    "#         # Filter the rows that match the target labels\n",
    "#         matching_df = df[df['label']==sztype]\n",
    "\n",
    "#         # Check if any label contains 'sz'\n",
    "#         if any(sztype in label for label in unique_labels):\n",
    "#             channels = extract_sz_channels(csv_file_path, sztype)\n",
    "#             # Create a modified dictionary based on the logic\n",
    "#             channels_presence = {szt: np.array([1 if electrode in chans else 0 for electrode in electrodes]).T for szt, chans in channels.items()}\n",
    "\n",
    "#             FOZ = channels_presence\n",
    "\n",
    "#     seiz_start = list(FOZ.keys())[0][0]\n",
    "#     seiz_stop = list(FOZ.keys())[0][1]\n",
    "#     # Strip the .edf extension and look for the corresponding .csv file\n",
    "#     base_name = os.path.splitext(csv_file_name)[0]\n",
    "            \n",
    "#     edf_file_name = base_name + '.edf'\n",
    "#     file_path = os.path.join(folder_path, edf_file_name)\n",
    "        \n",
    "#     # Read the EDF file\n",
    "#     raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "#     dat, times = raw[:]\n",
    "#     sfreq = int(raw.info['sfreq'])\n",
    "#     if seiz_stop-seiz_start>12:\n",
    "#         data = dat[:, int(round((seiz_start)*sfreq)):int(round((seiz_start+12)*sfreq))]\n",
    "#         chs = raw.ch_names\n",
    "#         # Extract the info from the original raw object to preserve metadata\n",
    "#         info = raw.info\n",
    "\n",
    "#         modified_raw = mne.io.RawArray(data, info)\n",
    "\n",
    "#         # Define channel selection and renaming\n",
    "#         if any('REF' in ch for ch in chs):\n",
    "#             ref_suffix = '-REF'\n",
    "#         else:\n",
    "#             ref_suffix = '-LE'\n",
    "\n",
    "#         selected_channels = [\n",
    "#             f'EEG FP1{ref_suffix}', f'EEG FP2{ref_suffix}', f'EEG F7{ref_suffix}', f'EEG F3{ref_suffix}',\n",
    "#             f'EEG FZ{ref_suffix}', f'EEG F4{ref_suffix}', f'EEG F8{ref_suffix}', f'EEG T3{ref_suffix}',\n",
    "#             f'EEG C3{ref_suffix}', f'EEG CZ{ref_suffix}', f'EEG C4{ref_suffix}', f'EEG T4{ref_suffix}',\n",
    "#             f'EEG T5{ref_suffix}', f'EEG P3{ref_suffix}', f'EEG PZ{ref_suffix}', f'EEG P4{ref_suffix}',\n",
    "#             f'EEG T6{ref_suffix}', f'EEG O1{ref_suffix}', f'EEG O2{ref_suffix}'\n",
    "#         ]\n",
    "\n",
    "#         rename_dict = {ch: ch.replace(f'EEG ', '').replace(ref_suffix, '') for ch in selected_channels}\n",
    "\n",
    "#         raw_selected = modified_raw.copy()\n",
    "        \n",
    "#         # Get the list of available channels\n",
    "#         available_channels = raw_selected.info[\"ch_names\"]\n",
    "\n",
    "#         # Find missing channels\n",
    "#         missing_channels = [ch for ch in selected_channels if ch not in available_channels]\n",
    "\n",
    "#         # Raise an error or handle missing channels\n",
    "#         if missing_channels==[]:\n",
    "#             # Select the specified channels\n",
    "#             raw_selected = raw_selected.pick_channels(selected_channels)\n",
    "\n",
    "#             # Apply renaming\n",
    "#             raw_selected.rename_channels(rename_dict)\n",
    "\n",
    "#             # Filter the data\n",
    "#             preprocEEG = raw_selected.copy()\n",
    "#             # Band-pass filter the data using a 6th-order Butterworth filter with filtfilt applied\n",
    "#             preprocEEG.filter(l_freq=1.0, h_freq=40, method='iir', iir_params=iir_params, phase='zero')\n",
    "#             # Notch filter to remove power line noise (assuming 60 Hz)\n",
    "#             preprocEEG.notch_filter(freqs=60.0)\n",
    "\n",
    "#             eegICA = preprocEEG\n",
    "\n",
    "#             eegICA.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "#             eeg_data, times = eegICA[:]\n",
    "#             eeg_epochs, n_epochs = epoch_data(eeg_data, sfreq, epoch_length)\n",
    "\n",
    "#             features = np.zeros((n_segments, n_channels, n_freqs))\n",
    "#             for g, segment in enumerate(eeg_epochs):\n",
    "#                 features[g] = compute_log_fft_features(segment)\n",
    "\n",
    "#             eegssp.append(features)\n",
    "\n",
    "# import pickle\n",
    "# # Save to a file\n",
    "# with open('f.pkl', 'wb') as f:\n",
    "#     pickle.dump(eegsf, f)\n",
    "# with open('g.pkl', 'wb') as f:\n",
    "#     pickle.dump(eegsg, f)\n",
    "# with open('cp.pkl', 'wb') as f:\n",
    "#     pickle.dump(eegscp, f)\n",
    "# with open('a.pkl', 'wb') as f:\n",
    "#     pickle.dump(eegsa, f)\n",
    "# with open('t.pkl', 'wb') as f:\n",
    "#     pickle.dump(eegst, f)\n",
    "# with open('tc.pkl', 'wb') as f:\n",
    "#     pickle.dump(eegstc, f)\n",
    "# with open('sp.pkl', 'wb') as f:\n",
    "#     pickle.dump(eegssp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0dcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n",
      "384\n",
      "5\n",
      "156\n",
      "11\n",
      "22\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('f.pkl', 'rb') as f:\n",
    "    eegsf = pickle.load(f)\n",
    "with open('g.pkl', 'rb') as f:\n",
    "    eegsg = pickle.load(f)\n",
    "with open('cp.pkl', 'rb') as f:\n",
    "    eegscp = pickle.load(f)\n",
    "with open('a.pkl', 'rb') as f:\n",
    "    eegsa = pickle.load(f)\n",
    "with open('t.pkl', 'rb') as f:\n",
    "    eegst = pickle.load(f)\n",
    "with open('tc.pkl', 'rb') as f:\n",
    "    eegstc = pickle.load(f)\n",
    "with open('sp.pkl', 'rb') as f:\n",
    "    eegssp = pickle.load(f)\n",
    "    \n",
    "y1 = len(eegsf)\n",
    "y2 = len(eegsg)\n",
    "y3 = len(eegsa)\n",
    "y4 = len(eegscp)\n",
    "y5 = len(eegst)\n",
    "y6 = len(eegstc)\n",
    "y7 = len(eegssp)\n",
    "\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "print(y4)\n",
    "print(y5)\n",
    "print(y6)\n",
    "print(y7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ca28f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(19, 19)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('adj_mx_3d.pkl', 'rb') as file:\n",
    "    adjdata = pickle.load(file)\n",
    "\n",
    "print(type(adjdata))\n",
    "print(adjdata[2].shape)\n",
    "adj_mat = adjdata[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd560c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EEG FP1',\n",
       "  'EEG FP2',\n",
       "  'EEG F3',\n",
       "  'EEG F4',\n",
       "  'EEG C3',\n",
       "  'EEG C4',\n",
       "  'EEG P3',\n",
       "  'EEG P4',\n",
       "  'EEG O1',\n",
       "  'EEG O2',\n",
       "  'EEG F7',\n",
       "  'EEG F8',\n",
       "  'EEG T3',\n",
       "  'EEG T4',\n",
       "  'EEG T5',\n",
       "  'EEG T6',\n",
       "  'EEG FZ',\n",
       "  'EEG CZ',\n",
       "  'EEG PZ'],\n",
       " {'EEG FP1': 0,\n",
       "  'EEG FP2': 1,\n",
       "  'EEG F3': 2,\n",
       "  'EEG F4': 3,\n",
       "  'EEG C3': 4,\n",
       "  'EEG C4': 5,\n",
       "  'EEG P3': 6,\n",
       "  'EEG P4': 7,\n",
       "  'EEG O1': 8,\n",
       "  'EEG O2': 9,\n",
       "  'EEG F7': 10,\n",
       "  'EEG F8': 11,\n",
       "  'EEG T3': 12,\n",
       "  'EEG T4': 13,\n",
       "  'EEG T5': 14,\n",
       "  'EEG T6': 15,\n",
       "  'EEG FZ': 16,\n",
       "  'EEG CZ': 17,\n",
       "  'EEG PZ': 18},\n",
       " array([[1.        , 0.24243228, 0.24135648, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.24237573, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.08801569, 0.        , 0.        ],\n",
       "        [0.24243228, 1.        , 0.        , 0.24135648, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.24237573, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.08801569, 0.        , 0.        ],\n",
       "        [0.24135648, 0.        , 1.        , 0.        , 0.14517006,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.30257306, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.27650845, 0.        , 0.        ],\n",
       "        [0.        , 0.24135648, 0.        , 1.        , 0.        ,\n",
       "         0.14517006, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.30257306, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.27650845, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.14517006, 0.        , 1.        ,\n",
       "         0.        , 0.14517006, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.11379092, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.11379092, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.14517006, 0.        ,\n",
       "         1.        , 0.        , 0.14517006, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.11379092, 0.        ,\n",
       "         0.        , 0.        , 0.11379092, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.14517006,\n",
       "         0.        , 1.        , 0.        , 0.24135648, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.30257306,\n",
       "         0.        , 0.        , 0.        , 0.27650845],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.14517006, 0.        , 1.        , 0.        , 0.24135648,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.30257306, 0.        , 0.        , 0.27650845],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.24135648, 0.        , 1.        , 0.24243228,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.24237573,\n",
       "         0.        , 0.        , 0.        , 0.08801569],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.24135648, 0.24243228, 1.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.24237573, 0.        , 0.        , 0.08801569],\n",
       "        [0.24237573, 0.        , 0.30257306, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.24237305, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.24237573, 0.        , 0.30257306, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.        , 0.24237305, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.11379092,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.24237305, 0.        , 1.        , 0.        , 0.24237305,\n",
       "         0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.11379092, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.24237305, 0.        , 1.        , 0.        ,\n",
       "         0.24237305, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.30257306, 0.        , 0.24237573, 0.        ,\n",
       "         0.        , 0.        , 0.24237305, 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.30257306, 0.        , 0.24237573,\n",
       "         0.        , 0.        , 0.        , 0.24237305, 0.        ,\n",
       "         1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.08801569, 0.08801569, 0.27650845, 0.27650845, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.11379092, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.11379092,\n",
       "         0.11379092, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.11379092, 1.        , 0.11379092],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.27650845, 0.27650845, 0.08801569, 0.08801569,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.11379092, 1.        ]], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8485c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some code are adapted from https://github.com/liyaguang/DCRNN\n",
    "and https://github.com/xlwang233/pytorch-DCRNN, which are\n",
    "licensed under the MIT License.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from data.data_utils import computeFFT\n",
    "from model.cell import DCGRUCell\n",
    "from torch.autograd import Variable\n",
    "import utils\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "\n",
    "def apply_tuple(tup, fn):\n",
    "    \"\"\"Apply a function to a Tensor or a tuple of Tensor\n",
    "    \"\"\"\n",
    "    if isinstance(tup, tuple):\n",
    "        return tuple((fn(x) if isinstance(x, torch.Tensor) else x)\n",
    "                     for x in tup)\n",
    "    else:\n",
    "        return fn(tup)\n",
    "\n",
    "\n",
    "def concat_tuple(tups, dim=0):\n",
    "    \"\"\"Concat a list of Tensors or a list of tuples of Tensor\n",
    "    \"\"\"\n",
    "    if isinstance(tups[0], tuple):\n",
    "        return tuple(\n",
    "            (torch.cat(\n",
    "                xs,\n",
    "                dim) if isinstance(\n",
    "                xs[0],\n",
    "                torch.Tensor) else xs[0]) for xs in zip(\n",
    "                *\n",
    "                tups))\n",
    "    else:\n",
    "        return torch.cat(tups, dim)\n",
    "\n",
    "\n",
    "class DCRNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, max_diffusion_step,\n",
    "                 hid_dim, num_nodes, num_rnn_layers,\n",
    "                 dcgru_activation=None, filter_type='laplacian',\n",
    "                 device=None):\n",
    "        super(DCRNNEncoder, self).__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self._device = device\n",
    "\n",
    "        encoding_cells = list()\n",
    "        # the first layer has different input_dim\n",
    "        encoding_cells.append(\n",
    "            DCGRUCell(\n",
    "                input_dim=input_dim,\n",
    "                num_units=hid_dim,\n",
    "                max_diffusion_step=max_diffusion_step,\n",
    "                num_nodes=num_nodes,\n",
    "                nonlinearity=dcgru_activation,\n",
    "                filter_type=filter_type))\n",
    "\n",
    "        # construct multi-layer rnn\n",
    "        for _ in range(1, num_rnn_layers):\n",
    "            encoding_cells.append(\n",
    "                DCGRUCell(\n",
    "                    input_dim=hid_dim,\n",
    "                    num_units=hid_dim,\n",
    "                    max_diffusion_step=max_diffusion_step,\n",
    "                    num_nodes=num_nodes,\n",
    "                    nonlinearity=dcgru_activation,\n",
    "                    filter_type=filter_type))\n",
    "        self.encoding_cells = nn.ModuleList(encoding_cells)\n",
    "\n",
    "    def forward(self, inputs, initial_hidden_state, supports):\n",
    "        seq_length = inputs.shape[0]\n",
    "        batch_size = inputs.shape[1]\n",
    "        # (seq_length, batch_size, num_nodes*input_dim)\n",
    "        inputs = torch.reshape(inputs, (seq_length, batch_size, -1))\n",
    "\n",
    "        current_inputs = inputs\n",
    "        # the output hidden states, shape (num_layers, batch, outdim)\n",
    "        output_hidden = []\n",
    "        for i_layer in range(self.num_rnn_layers):\n",
    "            hidden_state = initial_hidden_state[i_layer]\n",
    "            output_inner = []\n",
    "            for t in range(seq_length):\n",
    "                _, hidden_state = self.encoding_cells[i_layer](\n",
    "                    supports, current_inputs[t, ...], hidden_state)\n",
    "                output_inner.append(hidden_state)\n",
    "            output_hidden.append(hidden_state)\n",
    "            current_inputs = torch.stack(output_inner, dim=0).to(\n",
    "                self._device)  # (seq_len, batch_size, num_nodes * rnn_units)\n",
    "        output_hidden = torch.stack(output_hidden, dim=0).to(\n",
    "            self._device)  # (num_layers, batch_size, num_nodes * rnn_units)\n",
    "        return output_hidden, current_inputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_rnn_layers):\n",
    "            init_states.append(self.encoding_cells[i].init_hidden(batch_size))\n",
    "        # (num_layers, batch_size, num_nodes * rnn_units)\n",
    "        return torch.stack(init_states, dim=0)\n",
    "\n",
    "\n",
    "class DCGRUDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, max_diffusion_step, num_nodes,\n",
    "                 hid_dim, output_dim, num_rnn_layers, dcgru_activation=None,\n",
    "                 filter_type='laplacian', device=None, dropout=0.0):\n",
    "        super(DCGRUDecoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.output_dim = output_dim\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self._device = device\n",
    "        self.dropout = dropout\n",
    "\n",
    "        cell = DCGRUCell(input_dim=hid_dim, num_units=hid_dim,\n",
    "                         max_diffusion_step=max_diffusion_step,\n",
    "                         num_nodes=num_nodes, nonlinearity=dcgru_activation,\n",
    "                         filter_type=filter_type)\n",
    "\n",
    "        decoding_cells = list()\n",
    "        # first layer of the decoder\n",
    "        decoding_cells.append(\n",
    "            DCGRUCell(\n",
    "                input_dim=input_dim,\n",
    "                num_units=hid_dim,\n",
    "                max_diffusion_step=max_diffusion_step,\n",
    "                num_nodes=num_nodes,\n",
    "                nonlinearity=dcgru_activation,\n",
    "                filter_type=filter_type))\n",
    "        # construct multi-layer rnn\n",
    "        for _ in range(1, num_rnn_layers):\n",
    "            decoding_cells.append(cell)\n",
    "\n",
    "        self.decoding_cells = nn.ModuleList(decoding_cells)\n",
    "        self.projection_layer = nn.Linear(self.hid_dim, self.output_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)  # dropout before projection layer\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            inputs,\n",
    "            initial_hidden_state,\n",
    "            supports,\n",
    "            teacher_forcing_ratio=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: shape (seq_len, batch_size, num_nodes, output_dim)\n",
    "            initial_hidden_state: the last hidden state of the encoder, shape (num_layers, batch, num_nodes * rnn_units)\n",
    "            supports: list of supports from laplacian or dual_random_walk filters\n",
    "            teacher_forcing_ratio: ratio for teacher forcing\n",
    "        Returns:\n",
    "            outputs: shape (seq_len, batch_size, num_nodes * output_dim)\n",
    "        \"\"\"\n",
    "        seq_length, batch_size, _, _ = inputs.shape\n",
    "        inputs = torch.reshape(inputs, (seq_length, batch_size, -1))\n",
    "\n",
    "        go_symbol = torch.zeros(\n",
    "            (batch_size,\n",
    "             self.num_nodes *\n",
    "             self.output_dim)).to(\n",
    "            self._device)\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(\n",
    "            seq_length,\n",
    "            batch_size,\n",
    "            self.num_nodes *\n",
    "            self.output_dim).to(\n",
    "            self._device)\n",
    "\n",
    "        current_input = go_symbol  # (batch_size, num_nodes * input_dim)\n",
    "        for t in range(seq_length):\n",
    "            next_input_hidden_state = []\n",
    "            for i_layer in range(0, self.num_rnn_layers):\n",
    "                hidden_state = initial_hidden_state[i_layer]\n",
    "                output, hidden_state = self.decoding_cells[i_layer](\n",
    "                    supports, current_input, hidden_state)\n",
    "                current_input = output\n",
    "                next_input_hidden_state.append(hidden_state)\n",
    "            initial_hidden_state = torch.stack(next_input_hidden_state, dim=0)\n",
    "\n",
    "            projected = self.projection_layer(self.dropout(\n",
    "                output.reshape(batch_size, self.num_nodes, -1)))\n",
    "            projected = projected.reshape(\n",
    "                batch_size, self.num_nodes * self.output_dim)\n",
    "            outputs[t] = projected\n",
    "\n",
    "            if teacher_forcing_ratio is not None:\n",
    "                teacher_force = random.random() < teacher_forcing_ratio  # a bool value\n",
    "                current_input = (inputs[t] if teacher_force else projected)\n",
    "            else:\n",
    "                current_input = projected\n",
    "\n",
    "        return outputs\n",
    "\n",
    "########## Model for seizure classification/detection ##########\n",
    "class DCRNNModel_classification(nn.Module):\n",
    "    def __init__(self, args, num_classes, device=None):\n",
    "        super(DCRNNModel_classification, self).__init__()\n",
    "\n",
    "        num_nodes = args.num_nodes\n",
    "        num_rnn_layers = args.num_rnn_layers\n",
    "        rnn_units = args.rnn_units\n",
    "        enc_input_dim = args.input_dim\n",
    "        max_diffusion_step = args.max_diffusion_step\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self.rnn_units = rnn_units\n",
    "        self._device = device\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.encoder = DCRNNEncoder(input_dim=enc_input_dim,\n",
    "                                    max_diffusion_step=max_diffusion_step,\n",
    "                                    hid_dim=rnn_units, num_nodes=num_nodes,\n",
    "                                    num_rnn_layers=num_rnn_layers,\n",
    "                                    dcgru_activation=args.dcgru_activation,\n",
    "                                    filter_type=args.filter_type)\n",
    "\n",
    "        self.fc = nn.Linear(rnn_units, num_classes)\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_seq, seq_lengths, supports):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_seq: input sequence, shape (batch, seq_len, num_nodes, input_dim)\n",
    "            seq_lengths: actual seq lengths w/o padding, shape (batch,)\n",
    "            supports: list of supports from laplacian or dual_random_walk filters\n",
    "        Returns:\n",
    "            pool_logits: logits from last FC layer (before sigmoid/softmax)\n",
    "        \"\"\"\n",
    "        batch_size, max_seq_len = input_seq.shape[0], input_seq.shape[1]\n",
    "\n",
    "        # (max_seq_len, batch, num_nodes, input_dim)\n",
    "        input_seq = torch.transpose(input_seq, dim0=0, dim1=1)\n",
    "\n",
    "        # initialize the hidden state of the encoder\n",
    "        init_hidden_state = self.encoder.init_hidden(\n",
    "            batch_size).to(self._device)\n",
    "\n",
    "        # last hidden state of the encoder is the context\n",
    "        # (max_seq_len, batch, rnn_units*num_nodes)\n",
    "        _, final_hidden = self.encoder(input_seq, init_hidden_state, supports)\n",
    "        # (batch_size, max_seq_len, rnn_units*num_nodes)\n",
    "        output = torch.transpose(final_hidden, dim0=0, dim1=1)\n",
    "\n",
    "        # extract last relevant output\n",
    "        last_out = utils.last_relevant_pytorch(\n",
    "            output, seq_lengths, batch_first=True)  # (batch_size, rnn_units*num_nodes)\n",
    "        # (batch_size, num_nodes, rnn_units)\n",
    "        last_out = last_out.view(batch_size, self.num_nodes, self.rnn_units)\n",
    "        last_out = last_out.to(self._device)\n",
    "\n",
    "        # final FC layer\n",
    "        logits = self.fc(self.relu(self.dropout(last_out)))\n",
    "\n",
    "        # max-pooling over nodes\n",
    "        pool_logits, _ = torch.max(logits, dim=1)  # (batch_size, num_classes)\n",
    "\n",
    "        return pool_logits\n",
    "########## Model for seizure classification/detection ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ebfb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined tonic\n",
    "eegsct = np.concatenate((np.array(eegst), np.array(eegstc)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9c8e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.random.choice(np.array(eegscp).shape[0], size=33, replace=False)\n",
    "\n",
    "# xd = np.concatenate((np.array(eegscp)[indices], eegsct), axis=0)\n",
    "# print(xd.shape)\n",
    "\n",
    "# y1 = np.zeros(((np.array(eegscp)[indices]).shape[0]))\n",
    "# y2 = np.ones(((np.array(eegsct)).shape[0]))\n",
    "\n",
    "# yl = np.concatenate((y1, y2))\n",
    "# print(yl.shape)\n",
    "\n",
    "# all_feats = xd\n",
    "# all_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "439c9df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1274,)\n",
      "(1274, 12, 19, 100)\n"
     ]
    }
   ],
   "source": [
    "xd = np.concatenate((np.array(eegsf), np.array(eegsg), np.array(eegscp), eegsct), axis=0)\n",
    "\n",
    "y1 = np.zeros(((np.array(eegsf)).shape[0]))\n",
    "y2 = np.ones(((np.array(eegsg)).shape[0]))\n",
    "y3 = 2*np.ones(((np.array(eegscp)).shape[0]))\n",
    "y4 = 3*np.ones(((eegsct).shape[0]))\n",
    "\n",
    "yl = np.concatenate((y1, y2, y3, y4))\n",
    "print(yl.shape)\n",
    "\n",
    "all_feats = xd\n",
    "print(all_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df669e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils  \n",
    "\n",
    "# ======= Define Fine-Tuning Model ======= #\n",
    "class NewDCRNNModel(nn.Module):\n",
    "    def __init__(self, pretrained_encoder, rnn_units, num_new_classes, device):\n",
    "        super(NewDCRNNModel, self).__init__()\n",
    "        self.encoder = pretrained_encoder\n",
    "        self.rnn_units = rnn_units\n",
    "        self.device = device\n",
    "\n",
    "        self.fc = nn.Linear(rnn_units, num_new_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, input_seq, seq_lengths, supports):\n",
    "        # input shape: (batch_size, seq_len, num_nodes, input_dim)\n",
    "        input_seq = input_seq.transpose(0, 1)  # => (seq_len, batch_size, num_nodes, input_dim)\n",
    "\n",
    "        batch_size, seq_len, num_nodes, _ = input_seq.shape[1], input_seq.shape[0], input_seq.shape[2], input_seq.shape[3]\n",
    "        init_hidden_state = self.encoder.init_hidden(batch_size).to(self.device)\n",
    "\n",
    "        _, final_hidden = self.encoder(input_seq, init_hidden_state, supports)\n",
    "        output = final_hidden.transpose(0, 1)  # => (batch_size, seq_len, rnn_units * num_nodes)\n",
    "\n",
    "        print(\"final_hidden shape:\", final_hidden.shape)\n",
    "        print(\"output shape:\", output.shape)\n",
    "\n",
    "        last_out = utils.last_relevant_pytorch(output, seq_lengths, batch_first=True)\n",
    "        last_out = last_out.view(batch_size, num_nodes, self.rnn_units).to(self.device)\n",
    "\n",
    "        print(\"last_out shape:\", last_out.shape)\n",
    "\n",
    "        logits = self.fc(self.relu(self.dropout(last_out)))  # => (batch_size, num_nodes, num_classes)\n",
    "        pooled_logits, _ = torch.max(logits, dim=1)  # max over nodes\n",
    "\n",
    "        return pooled_logits  # => (batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e46f63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "# ======= Setup ======= #\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from args import get_args  \n",
    "import sys\n",
    "sys.argv = [\n",
    "    'train.py',\n",
    "    '--task', 'classification',\n",
    "    '--graph_type', 'combined',                    \n",
    "    '--load_model_path', 'pretrained_distance_graph_12s.pth.tar'\n",
    "]\n",
    "args = get_args()\n",
    "\n",
    "model_full = DCRNNModel_classification(args, num_classes=4, device=device)\n",
    "checkpoint = torch.load('pretrained_distance_graph_12s.pth.tar', map_location=device)\n",
    "model_full.load_state_dict(checkpoint['model_state'], strict=False)\n",
    "pretrained_encoder = model_full.encoder\n",
    "\n",
    "# ======= Final Model ======= #\n",
    "pre_model = NewDCRNNModel(pretrained_encoder, rnn_units=64, num_new_classes=4, device=device).to(device)\n",
    "for param in pre_model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# ======= Compute Graph Supports ======= #\n",
    "def compute_graph_supports(adj_mat, filter_type='laplacian'):\n",
    "    supports = []\n",
    "    if filter_type == 'laplacian':\n",
    "        supports.append(utils.calculate_scaled_laplacian(adj_mat, lambda_max=None))\n",
    "    elif filter_type == 'dual_random_walk':\n",
    "        supports.append(utils.calculate_random_walk_matrix(adj_mat).T)\n",
    "        supports.append(utils.calculate_random_walk_matrix(adj_mat.T).T)\n",
    "    else:\n",
    "        raise ValueError('Unknown filter type')\n",
    "    supports = [torch.FloatTensor(s.toarray()).to(device) for s in supports]\n",
    "    return supports\n",
    "\n",
    "# ======= Dataset ======= #\n",
    "inputs = torch.FloatTensor(all_feats)  # (N, 12, 19, 100)\n",
    "labels = torch.LongTensor(yl)\n",
    "seq_lengths = torch.full((len(all_feats),), 12, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20a3095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 12, 1216])\n",
      "output shape: torch.Size([12, 12, 1216])\n",
      "last_out shape: torch.Size([12, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 14, 1216])\n",
      "output shape: torch.Size([14, 12, 1216])\n",
      "last_out shape: torch.Size([14, 19, 64])\n",
      "Epoch 1: Train Loss = 1.3739 | Val Loss = 1.4235\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 12, 1216])\n",
      "output shape: torch.Size([12, 12, 1216])\n",
      "last_out shape: torch.Size([12, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 14, 1216])\n",
      "output shape: torch.Size([14, 12, 1216])\n",
      "last_out shape: torch.Size([14, 19, 64])\n",
      "Epoch 2: Train Loss = 1.3679 | Val Loss = 1.4079\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "final_hidden shape: torch.Size([12, 16, 1216])\n",
      "output shape: torch.Size([16, 12, 1216])\n",
      "last_out shape: torch.Size([16, 19, 64])\n",
      "Test Accuracy: 0.5391\n"
     ]
    }
   ],
   "source": [
    "full_dataset = TensorDataset(inputs, labels, seq_lengths)\n",
    "train_size = int(0.6 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ======= Training ======= #\n",
    "optimizer = optim.Adam(pre_model.fc.parameters(), lr=1e-3)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=torch.unique(labels.cpu()).numpy(),\n",
    "                                     y=labels.cpu().numpy())\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "supports = compute_graph_supports(adj_mat)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 1\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(2):\n",
    "    pre_model.train()\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_labels, batch_seq_lengths in train_loader:\n",
    "        batch_inputs, batch_labels, batch_seq_lengths = batch_inputs.to(device), batch_labels.to(device), batch_seq_lengths.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pre_model(batch_inputs, batch_seq_lengths, supports)\n",
    "        loss = loss_fn(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    pre_model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels, val_seq_lengths in val_loader:\n",
    "            val_inputs, val_labels, val_seq_lengths = val_inputs.to(device), val_labels.to(device), val_seq_lengths.to(device)\n",
    "            val_outputs = pre_model(val_inputs, val_seq_lengths, supports)\n",
    "            val_loss += loss_fn(val_outputs, val_labels).item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(train_losses, label='Train Loss')\n",
    "# plt.plot(val_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss over Epochs')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# ======= Evaluation ======= #\n",
    "pre_model.eval()\n",
    "correct = 0\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_inputs, batch_labels, batch_seq_lengths in test_loader:\n",
    "        batch_inputs, batch_labels, batch_seq_lengths = batch_inputs.to(device), batch_labels.to(device), batch_seq_lengths.to(device)\n",
    "        outputs = pre_model(batch_inputs, batch_seq_lengths, supports)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        correct += (preds == batch_labels).sum().item()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "accuracy = correct / len(test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e149c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# After collecting all_preds and all_targets\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_targets, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def classwise_occlusion_analysis(\n",
    "    model, data_loader, adj_mat, device, \n",
    "    compute_supports_func, filter_type, num_classes\n",
    "):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    num_nodes = adj_mat.shape[0]\n",
    "    supports_orig = compute_supports_func(adj_mat, filter_type=filter_type)\n",
    "    supports_orig = [s.to(device) for s in supports_orig]\n",
    "\n",
    "    node_importance = {cls: defaultdict(float) for cls in range(num_classes)}\n",
    "    edge_importance = {cls: defaultdict(float) for cls in range(num_classes)}\n",
    "    class_counts = defaultdict(int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_seq_len in data_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_seq_len = batch_seq_len.to(device)\n",
    "\n",
    "            outputs = model(batch_x, batch_seq_len, supports_orig)\n",
    "            preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "\n",
    "            for i in range(batch_x.size(0)):\n",
    "                x_sample = batch_x[i:i+1]\n",
    "                y_true = batch_y[i].item()\n",
    "                class_counts[y_true] += 1\n",
    "\n",
    "                sl = batch_seq_len[i:i+1]\n",
    "                orig_out = model(x_sample, sl, supports_orig)\n",
    "                orig_prob = torch.softmax(orig_out, dim=1)[0, y_true].item()\n",
    "\n",
    "                # --- Node Occlusion ---\n",
    "                for node in range(num_nodes):\n",
    "                    x_occ = x_sample.clone()\n",
    "                    x_occ[:, :, node, :] = 0\n",
    "                    out_occ = model(x_occ, sl, supports_orig)\n",
    "                    occ_prob = torch.softmax(out_occ, dim=1)[0, y_true].item()\n",
    "                    drop = orig_prob - occ_prob\n",
    "                    node_importance[y_true][node] += drop\n",
    "\n",
    "                # --- Edge Occlusion ---\n",
    "                for s_idx, s in enumerate(supports_orig):\n",
    "                    for src in range(num_nodes):\n",
    "                        for tgt in range(num_nodes):\n",
    "                            if s[src, tgt] != 0:\n",
    "                                s_occ = [s_.clone() for s_ in supports_orig]\n",
    "                                s_occ[s_idx][src, tgt] = 0\n",
    "                                out_occ = model(x_sample, sl, s_occ)\n",
    "                                occ_prob = torch.softmax(out_occ, dim=1)[0, y_true].item()\n",
    "                                drop = orig_prob - occ_prob\n",
    "                                edge_importance[y_true][(src, tgt)] += drop\n",
    "\n",
    "    # Normalize\n",
    "    for cls in range(num_classes):\n",
    "        if class_counts[cls] > 0:\n",
    "            for node in node_importance[cls]:\n",
    "                node_importance[cls][node] /= class_counts[cls]\n",
    "            for edge in edge_importance[cls]:\n",
    "                edge_importance[cls][edge] /= class_counts[cls]\n",
    "\n",
    "    return node_importance, edge_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_imp, edge_imp = classwise_occlusion_analysis(\n",
    "    model=pre_model,\n",
    "    data_loader=test_loader,\n",
    "    adj_mat=adj_mat,\n",
    "    device=device,\n",
    "    compute_supports_func=compute_graph_supports,\n",
    "    filter_type='laplacian',\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "\n",
    "def get_spectral_graph_positions():\n",
    "    \"\"\"\n",
    "    # Get positions of EEG electrodes for visualizations\n",
    "    \"\"\"\n",
    "\n",
    "    adj_mx_all = adjdata\n",
    "    adj_mx = adj_mx_all[-1]\n",
    "\n",
    "    node_id_dict = adj_mx_all[1]\n",
    "\n",
    "    eeg_viz = nx.Graph()\n",
    "    adj_mx = adj_mx_all[-1]\n",
    "    node_id_label = collections.defaultdict()\n",
    "\n",
    "    for i in range(adj_mx.shape[0]):\n",
    "        eeg_viz.add_node(i)\n",
    "\n",
    "    for k, v in node_id_dict.items():\n",
    "        node_id_label[v] = k\n",
    "    # Add edges\n",
    "    for i in range(adj_mx.shape[0]):\n",
    "        for j in range(\n",
    "                adj_mx.shape[1]):  # do not include self-edge in visualization\n",
    "            if i != j and adj_mx[i, j] > 0:\n",
    "                eeg_viz.add_edge(i, j)\n",
    "\n",
    "    pos = nx.spectral_layout(eeg_viz)\n",
    "    # keep the nice shape of the electronodes on the scalp\n",
    "    pos_spec = {node: (y, -x) for (node, (x, y)) in pos.items()}\n",
    "\n",
    "    return pos_spec\n",
    "\n",
    "\n",
    "def draw_graph_weighted_edge(\n",
    "        adj_mx,\n",
    "        node_id_dict,\n",
    "        pos_spec,\n",
    "        is_directed,\n",
    "        title='',\n",
    "        save_dir=None,\n",
    "        fig_size=(\n",
    "            12,\n",
    "            8),\n",
    "    node_color='Red',\n",
    "    font_size=20,\n",
    "        plot_colorbar=False):\n",
    "    \"\"\"\n",
    "    Draw a graph with weighted edges\n",
    "    Args:\n",
    "        adj_mx: Adjacency matrix for the graph, shape (num_nodes, num_nodes\n",
    "        node_id_dict: dict, key is node name, value is node index\n",
    "        pos_spec: Graph node position specs from function get_spectral_graph_positions\n",
    "        is_directed: If True, draw directed graphs\n",
    "        title: str, title of the figure\n",
    "        save_dir: Dir to save the plot\n",
    "        fig_size: figure size\n",
    "\n",
    "    \"\"\"\n",
    "    eeg_viz = nx.DiGraph() if is_directed else nx.Graph()\n",
    "    node_id_label = collections.defaultdict()\n",
    "\n",
    "    for i in range(adj_mx.shape[0]):\n",
    "        eeg_viz.add_node(i)\n",
    "\n",
    "    for k, v in node_id_dict.items():\n",
    "        node_id_label[v] = k\n",
    "\n",
    "    # Add edges\n",
    "    for i in range(adj_mx.shape[0]):\n",
    "        for j in range(adj_mx.shape[1]):  # since it's now directed\n",
    "            if i != j and adj_mx[i, j] > 0:\n",
    "                eeg_viz.add_edge(i, j, weight=adj_mx[i, j])\n",
    "\n",
    "    edges, weights = zip(*nx.get_edge_attributes(eeg_viz, 'weight').items())\n",
    "\n",
    "    # Change the color scales below\n",
    "    k = 3\n",
    "    cmap = plt.cm.Greys(np.linspace(0, 1, (k + 1) * len(weights)))\n",
    "    cmap = matplotlib.colors.ListedColormap(cmap[len(weights):-1:(k - 1)])\n",
    "\n",
    "    plt.figure(figsize=fig_size)\n",
    "    nx.draw_networkx(eeg_viz, pos_spec, labels=node_id_label, with_labels=True,\n",
    "                     edgelist=edges, edge_color=rankdata(weights),\n",
    "                     width=fig_size[1] / 2, edge_cmap=cmap, font_weight='bold',\n",
    "                     node_color=node_color,\n",
    "                     node_size=250 * (fig_size[0] + fig_size[1]),\n",
    "                     font_color='white',\n",
    "                     font_size=font_size)\n",
    "    plt.title(title, fontsize=font_size)\n",
    "    plt.axis('off')\n",
    "    if plot_colorbar:\n",
    "        sm = plt.cm.ScalarMappable(\n",
    "            cmap=cmap, norm=plt.Normalize(\n",
    "                vmin=0, vmax=1))\n",
    "        sm.set_array([])\n",
    "        plt.colorbar(sm)\n",
    "    plt.tight_layout()\n",
    "    if save_dir is not None:\n",
    "        plt.savefig(save_dir, dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_importance_graph(adj_mx_data, node_importance, edge_importance, class_label='Class', figsize=(12, 8)):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import networkx as nx\n",
    "\n",
    "    # Load adj matrix\n",
    "    adj_mx = adj_mx_data[2]\n",
    "    node_id_dict = {k.split(' ')[-1]: v for k, v in adj_mx_data[1].items()}\n",
    "    pos_spec = get_spectral_graph_positions()\n",
    "\n",
    "    # Invert the mapping: index â†’ label\n",
    "    node_labels = {v: k for k, v in node_id_dict.items()}\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for i in range(adj_mx.shape[0]):\n",
    "        G.add_node(i)\n",
    "\n",
    "    for i in range(adj_mx.shape[0]):\n",
    "        for j in range(adj_mx.shape[1]):\n",
    "            if i != j and adj_mx[i, j] > 0:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    # Normalize node and edge importances\n",
    "    node_colors = np.array([node_importance.get(i, 0.0) for i in range(adj_mx.shape[0])])\n",
    "    edge_colors = np.array([edge_importance.get((i, j), 0.0) for i, j in G.edges()])\n",
    "\n",
    "    # Normalize for color mapping\n",
    "    node_vmin, node_vmax = node_colors.min(), node_colors.max()\n",
    "    edge_vmin, edge_vmax = edge_colors.min(), edge_colors.max()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        G, pos_spec, node_color=node_colors, cmap='Reds',\n",
    "        node_size=1200, ax=ax, vmin=node_vmin, vmax=node_vmax\n",
    "    )\n",
    "    edges = nx.draw_networkx_edges(\n",
    "        G, pos_spec, edge_color=edge_colors, edge_cmap=plt.cm.Blues,\n",
    "        width=3, ax=ax, edge_vmin=edge_vmin, edge_vmax=edge_vmax\n",
    "    )\n",
    "    nx.draw_networkx_labels(G, pos_spec, labels=node_labels, font_color='black', ax=ax, font_size=12)\n",
    "    ax.set_title(f\"Importance Visualization - {class_label}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add colorbars with correct axes context\n",
    "    sm_nodes = plt.cm.ScalarMappable(cmap='Reds', norm=plt.Normalize(vmin=node_vmin, vmax=node_vmax))\n",
    "    sm_nodes.set_array([])\n",
    "    plt.colorbar(sm_nodes, ax=ax, orientation='vertical', label='Node Importance')\n",
    "\n",
    "    sm_edges = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=edge_vmin, vmax=edge_vmax))\n",
    "    sm_edges.set_array([])\n",
    "    plt.colorbar(sm_edges, ax=ax, orientation='vertical', label='Edge Importance')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = 0\n",
    "visualize_importance_graph(adjdata, node_imp[class_id], edge_imp[class_id], class_label=f\"Class {class_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = 1\n",
    "visualize_importance_graph(adjdata, node_imp[class_id], edge_imp[class_id], class_label=f\"Class {class_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc0a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
