{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script Name: Focal_Graphs\n",
    "\n",
    "Author: Fatemeh Delavari  \n",
    "Version: 2.0 (11/25/2024)  \n",
    "Description: Calculates connectivity and constructs graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "import networkx as nx\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from scipy.signal import hilbert, butter, filtfilt\n",
    "from mne.preprocessing import ICA\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.stats import norm\n",
    "from scipy.signal import hann, periodogram\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.signal import welch\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants\n",
    "num_channels = 19\n",
    "epoch_length = 1  # in seconds\n",
    "n_nodes = 19\n",
    "\n",
    "# Constants for bad segment detection\n",
    "disconnection_threshold = 1e-10  # Threshold for detecting disconnection\n",
    "constant_threshold = 1e-10  # Allow for small variations to detect constant data\n",
    "min_duration = 10  # Minimum duration (in samples) to consider a segment as bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify channels\n",
    "simplified_names = [\n",
    "    'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4',\n",
    "    'T5', 'T6', 'FZ', 'CZ', 'PZ'\n",
    "]\n",
    "\n",
    "# Define positions (in meters) for the channels\n",
    "pos = {'FP1': (-0.03, 0.08, 0.05),\n",
    "'FP2': (0.03, 0.08, 0.05),\n",
    "'F3': (-0.04, 0.04, 0.06),\n",
    "'F4': (0.04, 0.04, 0.06),\n",
    "'C3': (-0.05, 0.00, 0.04),\n",
    "'C4': (0.05, 0.00, 0.04),\n",
    "'P3': (-0.04, -0.04, 0.03),\n",
    "'P4': (0.04, -0.04, 0.03),\n",
    "'O1': (-0.03, -0.08, 0.02),\n",
    "'O2': (0.03, -0.08, 0.02),\n",
    "'F7': (-0.07, 0.05, 0.06),\n",
    "'F8': (0.07, 0.05, 0.06),\n",
    "'T3': (-0.08, 0.00, 0.04),\n",
    "'T4': (0.08, 0.00, 0.04),\n",
    "'T5': (-0.06, -0.05, 0.03),\n",
    "'T6': (0.06, -0.05, 0.03),\n",
    "'FZ': (0.00, 0.03, 0.07),\n",
    "'CZ': (0.00, 0.00, 0.06),\n",
    "'PZ': (0.00, -0.03, 0.05)}\n",
    "\n",
    "colors = [\n",
    "    '#1f77b4',  # Blue\n",
    "    '#ff7f0e',  # Orange\n",
    "    '#2ca02c',  # Green\n",
    "    '#d62728',  # Red\n",
    "    '#9467bd',  # Purple\n",
    "    '#8c564b',  # Brown\n",
    "    '#e377c2',  # Pink\n",
    "    '#7f7f7f',  # Gray\n",
    "    '#bcbd22',  # Yellow-Green\n",
    "    '#17becf',  # Cyan\n",
    "    '#ff5733',  # Bright Orange\n",
    "    '#33ff57',  # Lime Green\n",
    "    '#5733ff',  # Violet\n",
    "    '#ff33a8',  # Hot Pink\n",
    "    '#a8ff33',  # Neon Green\n",
    "    '#33a8ff',  # Sky Blue\n",
    "    '#ff3380',  # Raspberry\n",
    "    '#80ff33',  # Bright Lime\n",
    "    '#3380ff',  # Royal Blue\n",
    "    '#ffdf33'   # Gold\n",
    "]\n",
    "\n",
    "# Define the Butterworth filter parameters with filtfilt applied\n",
    "iir_params = dict(order=6, ftype='butter', output='sos')\n",
    "\n",
    "frequency_bands = {\n",
    "    # \"Delta\": [2, 4],\n",
    "    # \"Theta\": [4, 8],\n",
    "    \"Alpha\": [8, 13],\n",
    "    # \"Beta\": [13, 30],\n",
    "    # \"Gamma\": [30, 40]\n",
    "}\n",
    "\n",
    "# # List of target labels (case-insensitive)\n",
    "# target_labels = ['bckg', 'seiz', 'fnsz', 'gnsz', 'spsz', 'cpsz', 'absz', \n",
    "#                  'tnsz', 'cnsz', 'tcsz', 'atsz', 'mysz', 'nesz']\n",
    "\n",
    "# List of target labels (case-insensitive)\n",
    "target_labels = ['fnsz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect bad (saturated, disconnected, or constant) segments\n",
    "def find_bad_segments(channel_data, saturation_threshold, disconnection_threshold, constant_threshold, min_duration, constant_duration):\n",
    "    # Detect saturated and disconnected segments\n",
    "    is_saturated = np.abs(channel_data) > saturation_threshold\n",
    "    is_disconnected = np.abs(channel_data) < disconnection_threshold\n",
    "    \n",
    "    # Detect constant segments\n",
    "    diffs = np.abs(np.diff(channel_data)) < constant_threshold  # Small differences\n",
    "    is_constant = np.convolve(diffs.astype(int), np.ones(constant_duration), 'valid') == constant_duration\n",
    "\n",
    "    is_constant = np.zeros_like(channel_data, dtype=bool)\n",
    "    \n",
    "    for i in range(len(diffs) - constant_duration + 1):\n",
    "        if np.all(diffs[i:i + constant_duration]):\n",
    "            is_constant[i:i + constant_duration] = True\n",
    "        \n",
    "    # Combine all conditions\n",
    "    is_bad = is_saturated | is_disconnected | is_constant\n",
    "    convolved = np.convolve(is_bad, np.ones(min_duration), 'valid')\n",
    "    bad_segments = np.where(convolved >= min_duration)[0]\n",
    "    return bad_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpolate bad segments using neighboring channels\n",
    "def interpolate_using_neighbors(eeg_data, bad_segments, min_duration):\n",
    "    for segment_start in bad_segments:\n",
    "        segment_end = segment_start + min_duration\n",
    "\n",
    "        # Identify bad channels in this segment\n",
    "        bad_channels = np.all(np.abs(eeg_data[:, segment_start:segment_end]) > saturation_threshold, axis=1) | \\\n",
    "                    np.all(np.abs(eeg_data[:, segment_start:segment_end]) < disconnection_threshold, axis=1) | \\\n",
    "                    np.all(np.abs(np.diff(eeg_data[:, segment_start:segment_end])) < constant_threshold, axis=1)\n",
    "\n",
    "        # # If all channels are bad, and the segment is at the beginning or end, remove it\n",
    "        # if np.all(bad_channels):\n",
    "        #     if segment_start == 0 or segment_end == eeg_data.shape[1]:\n",
    "        #         eeg_data = np.delete(eeg_data, slice(segment_start, segment_end), axis=1)\n",
    "        #     continue  # Skip interpolation as segment was removed\n",
    "\n",
    "        # Interpolate bad segments using good channels\n",
    "        for channel_idx in range(eeg_data.shape[0]):\n",
    "            if bad_channels[channel_idx]:\n",
    "                good_channels = np.where(~bad_channels)[0]\n",
    "                \n",
    "                # If there are valid channels to interpolate from, proceed\n",
    "                if len(good_channels) > 0:\n",
    "                    eeg_data[channel_idx, segment_start:segment_end] = np.mean(\n",
    "                        eeg_data[good_channels, segment_start:segment_end], axis=0)\n",
    "                else:\n",
    "                    eeg_data = np.delete(eeg_data, slice(segment_start, segment_end), axis=1)\n",
    "    return eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to bandpass filter the data\n",
    "def bandpass_filter(data, sfreq, low_freq, high_freq):\n",
    "    \"\"\"\n",
    "    Band-pass filter the data.\n",
    "    \n",
    "    Parameters:\n",
    "    data (ndarray): The input signal of shape (n_channels, n_times)\n",
    "    sfreq (float): The sampling frequency\n",
    "    low_freq (float): The lower bound of the frequency range\n",
    "    high_freq (float): The upper bound of the frequency range\n",
    "    \n",
    "    Returns:\n",
    "    filtered_data (ndarray): The band-pass filtered signal\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * sfreq\n",
    "    low = low_freq / nyquist\n",
    "    high = high_freq / nyquist\n",
    "    b, a = butter(4, [low, high], btype='band')\n",
    "    filtered_data = filtfilt(b, a, data, axis=1)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate PLV\n",
    "def calculate_plv(phasedata):\n",
    "    \"\"\"\n",
    "    Calculate the Phase Locking Value (PLV) between pairs of EEG channels.\n",
    "    \n",
    "    Parameters:\n",
    "    eeg_data (ndarray): EEG data of shape (n_channels, n_times)\n",
    "    sfreq (float): Sampling frequency of the EEG data\n",
    "    low_freq (float): Lower frequency bound for band-pass filter (default 8 Hz)\n",
    "    high_freq (float): Upper frequency bound for band-pass filter (default 13 Hz)\n",
    "    \n",
    "    Returns:\n",
    "    plv_matrix (ndarray): PLV matrix of shape (n_channels, n_channels)\n",
    "    \"\"\"\n",
    "    n_channels, n_times = phasedata.shape\n",
    "    plv_matrix = np.ones((n_channels, n_channels))\n",
    "    plv_array = np.ones((round(n_channels*(n_channels - 1)/2)))\n",
    "    \n",
    "    k = 0\n",
    "    # Calculate PLV\n",
    "    for i in range(n_channels):\n",
    "        for j in range(i + 1, n_channels):\n",
    "            phase_diff = phasedata[i] - phasedata[j]\n",
    "            plv = np.abs(np.sum(np.exp(1j * phase_diff)) / n_times)\n",
    "            plv_matrix[i, j] = plv\n",
    "            plv_matrix[j, i] = plv  # PLV is symmetric\n",
    "            plv_array[k] = plv\n",
    "            k = k + 1\n",
    "    return plv_array, plv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create graph from PLV matrix\n",
    "def create_graph(plv_matrix, ch_names):\n",
    "    G = nx.Graph()\n",
    "    for i, ch1 in enumerate(ch_names):\n",
    "        for j, ch2 in enumerate(ch_names):\n",
    "            if i < j:  # To avoid duplicate edges\n",
    "                weight = plv_matrix[i, j]\n",
    "                G.add_edge(ch1, ch2, weight=weight)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create graph from PLV matrix\n",
    "def create_graph_bi(plv_matrix, ch_names):\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for i, ch1 in enumerate(ch_names):\n",
    "        for j, ch2 in enumerate(ch_names):\n",
    "            if i < j:  # To avoid duplicate edges\n",
    "                weight = plv_matrix[i, j]\n",
    "                if weight == 1:\n",
    "                    G.add_edge(ch1, ch2, weight=1)  # Binary edge\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to epoch data\n",
    "def epoch_data(data, sfreq, epoch_length):\n",
    "    n_channels, n_samples = data.shape\n",
    "    epoch_samples = int(epoch_length * sfreq)\n",
    "    n_epochs = n_samples // epoch_samples\n",
    "    epochs = np.array_split(data[:, :n_epochs * epoch_samples], n_epochs, axis=1)\n",
    "    return epochs, n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder path containing the EDF files\n",
    "folder_path = 'C:/Users/Atena/Documents/edf'\n",
    "# Specify the folder path containing the CSV files\n",
    "folder_path_csv = 'C:/Users/Atena/Documents/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num = -1\n",
    "re = []\n",
    "fsz_containing = []\n",
    "# Define a dictionary to store the data for all files\n",
    "all_data = {}\n",
    "\n",
    "# Loop through all the EDF files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.edf'):  # Check if the file is an EDF file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        file_num = file_num + 1\n",
    "        print(f\"Processing file number: {file_num}\")\n",
    "\n",
    "        # Strip the .edf extension and look for the corresponding .csv file\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        csv_file_name = base_name + '.csv'\n",
    "                \n",
    "        # Check if the corresponding CSV file exists\n",
    "        if csv_file_name in os.listdir(folder_path_csv):\n",
    "            csv_file_path = os.path.join(folder_path_csv, csv_file_name)\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(csv_file_path, comment='#') \n",
    "\n",
    "            # Extract the unique labels from the 'label' column, ignoring case sensitivity\n",
    "            unique_labels = df['label'].str.lower().unique()\n",
    "\n",
    "            # Find matching labels (case-insensitive comparison)\n",
    "            matching_labels = [label for label in unique_labels if label in target_labels]\n",
    "\n",
    "            # Convert the label column to lowercase for case-insensitive matching\n",
    "            df['label'] = df['label'].str.lower()\n",
    "\n",
    "            # Filter the rows that match the target labels\n",
    "            matching_df = df[df['label'].isin(target_labels)]\n",
    "\n",
    "            # Check if any label contains 'sz'\n",
    "            if any('fnsz' in label for label in unique_labels):\n",
    "                fsz_containing.append(file_num)\n",
    "            \n",
    "                # Read the EDF file\n",
    "                raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "                data, times = raw[:]\n",
    "                sfreq = int(raw.info['sfreq'])\n",
    "                chs = raw.ch_names\n",
    "                # Extract the info from the original raw object to preserve metadata\n",
    "                info = raw.info\n",
    "                saturation_threshold = 10*np.std(data)  \n",
    "                constant_duration = int(sfreq)  # At least 1 second of constant data (250 samples)\n",
    "\n",
    "                # Find and interpolate or remove bad segments for each channel\n",
    "                bad_segments_all = set()\n",
    "                for channel_idx in range(data.shape[0]):\n",
    "                    bad_segments = find_bad_segments(data[channel_idx], saturation_threshold, disconnection_threshold, constant_threshold, min_duration, constant_duration)\n",
    "                    bad_segments_all.update(bad_segments)\n",
    "                # Interpolate or remove segments based on conditions\n",
    "                modified_eeg_data = interpolate_using_neighbors(data, list(bad_segments_all), min_duration)\n",
    "                # Output the modified EEG data\n",
    "                print(f\"Modified EEG data shape: {modified_eeg_data.shape}\")\n",
    "                # Create a new raw object with the modified data\n",
    "                modified_raw = mne.io.RawArray(modified_eeg_data, info)\n",
    "\n",
    "                if any('REF' in channel for channel in chs):\n",
    "                    selected_channels = ['EEG FP1-REF', 'EEG FP2-REF', 'EEG F7-REF', 'EEG F3-REF', \n",
    "                            'EEG FZ-REF', 'EEG F4-REF', 'EEG F8-REF', 'EEG T3-REF', \n",
    "                            'EEG C3-REF', 'EEG CZ-REF', 'EEG C4-REF', 'EEG T4-REF', \n",
    "                            'EEG T5-REF', 'EEG P3-REF', 'EEG PZ-REF', 'EEG P4-REF',\n",
    "                            'EEG T6-REF', 'EEG O1-REF', 'EEG O2-REF']\n",
    "                    montage_positions = {ch_name: np.array(pos[ch_name.replace('EEG ', '').replace('-REF', '')])\n",
    "                            for ch_name in selected_channels}\n",
    "                else:\n",
    "                    selected_channels = ['EEG FP1-LE', 'EEG FP2-LE', 'EEG F7-LE', 'EEG F3-LE', 'EEG FZ-LE', 'EEG F4-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG C3-LE', 'EEG CZ-LE', 'EEG C4-LE', 'EEG T4-LE', 'EEG T5-LE', 'EEG P3-LE', 'EEG PZ-LE', 'EEG P4-LE', 'EEG T6-LE', 'EEG O1-LE', 'EEG O2-LE']\n",
    "                    # montage_positions = {ch_name: np.array(pos[ch_name.replace('EEG ', '').replace('-LE', '')])\n",
    "                    #         for ch_name in selected_channels}\n",
    "                raw_selected = modified_raw.copy()\n",
    "                # Select the specified channels\n",
    "                raw_selected = raw_selected.pick_channels(selected_channels)\n",
    "\n",
    "                # Filter the data\n",
    "                preprocEEG = raw_selected.copy()\n",
    "                # Band-pass filter the data using a 6th-order Butterworth filter with filtfilt applied\n",
    "                preprocEEG.filter(l_freq=1.0, h_freq=40, method='iir', iir_params=iir_params, phase='zero')\n",
    "                # Notch filter to remove power line noise (assuming 60 Hz)\n",
    "                preprocEEG.notch_filter(freqs=60.0)\n",
    "\n",
    "                # Applying ICA: Create a custom montage\n",
    "                montage = mne.channels.make_dig_montage(ch_pos=montage_positions, coord_frame='head')\n",
    "                # Apply the montage to the data\n",
    "                preprocEEG.set_montage(montage)\n",
    "                eegICA = preprocEEG.copy()\n",
    "                # Set up the ICA object, specifying the number of components to compute\n",
    "                ica = ICA(n_components=19, random_state=97, max_iter=1000)\n",
    "                # Fit ICA to the raw data\n",
    "                ica.fit(eegICA)\n",
    "                emg_inds, scores = ica.find_bads_muscle(eegICA, threshold = 0.95)\n",
    "                ica.exclude.extend(emg_inds)\n",
    "                # Apply the ICA to the raw data\n",
    "                ica.apply(eegICA)\n",
    "\n",
    "                eegICA = preprocEEG\n",
    "\n",
    "                eegICA.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "                eeg_data, times = eegICA[:]\n",
    "\n",
    "                # duration_seconds = eeg_data.shape[1] / sampfreq\n",
    "\n",
    "                epoch_samples = int(epoch_length * sfreq)\n",
    "            \n",
    "                freq_num = 0\n",
    "                for band, freq_range in frequency_bands.items():\n",
    "                    freq_num = freq_num + 1\n",
    "                    low_freq, high_freq = freq_range\n",
    "                    # Band-pass filter the data in the specified frequency band\n",
    "                    # eeg_data_filtered = bandpass_filter(eeg_data[:, 1300 * sfreq:1330 * sfreq], sfreq, low_freq, high_freq)\n",
    "                    eeg_data_filtered = bandpass_filter(eeg_data, sfreq, low_freq, high_freq)\n",
    "                    # Compute the analytic signal (Hilbert transform) to get the phase\n",
    "                    analytic_signal = hilbert(eeg_data_filtered, axis=1)\n",
    "                    phase_data = np.angle(analytic_signal)\n",
    "                    phase_epochs, n_epochs  = epoch_data(phase_data[:19, :], sfreq, epoch_length)\n",
    "                    plv_array = np.zeros((19*9, n_epochs, high_freq-low_freq+1))\n",
    "                    plv_matrix = np.zeros((19, 19, n_epochs, high_freq-low_freq+1))\n",
    "\n",
    "                    for freq in range(low_freq, high_freq+1):\n",
    "                        freq_n = freq-low_freq\n",
    "                        # Band-pass filter the data in the specified frequency band\n",
    "                        # eeg_data_filtered = bandpass_filter(eeg_data[:, 1300 * sfreq:1330 * sfreq], sfreq, freq-1, freq+1)\n",
    "                        eeg_data_filtered = bandpass_filter(eeg_data, sfreq, freq-1, freq+1)\n",
    "                        # Compute the analytic signal (Hilbert transform) to get the phase\n",
    "                        analytic_signal = hilbert(eeg_data_filtered, axis=1)\n",
    "                        phase_data = np.angle(analytic_signal)\n",
    "                        phase_epochs, n_epochs = epoch_data(phase_data, sfreq, epoch_length)\n",
    "                        epoch_n = 0\n",
    "                        for epoch in phase_epochs:\n",
    "                            plv_array[:, epoch_n, freq_n], plv_matrix[:, :, epoch_n, freq_n] = calculate_plv(epoch)\n",
    "                            epoch_n = epoch_n + 1\n",
    "                    plv_all = np.mean(plv_array, axis = 2)\n",
    "                    plv_all_matrix = np.mean(plv_matrix, axis = 3)\n",
    "\n",
    "                    graphs = []\n",
    "                    epoch_n = 0\n",
    "                    for epoch in phase_epochs:\n",
    "                        graph = create_graph(plv_all_matrix[:, :, epoch_n], selected_channels)\n",
    "                        graphs.append(graph)\n",
    "                        epoch_n = epoch_n + 1\n",
    "\n",
    "                    plv_bi = (plv_all>0.7).astype(int)\n",
    "\n",
    "                    ratio_edge = np.sum(plv_bi)/plv_bi.size\n",
    "                    print('Ratio Edges =', ratio_edge)\n",
    "                    re.append(ratio_edge)\n",
    "                    \n",
    "                    plv_bi_matrix = (plv_all_matrix>0.7).astype(int)\n",
    "                    graphs_bi = []\n",
    "                    epoch_n = 0\n",
    "                    for epoch in phase_epochs:\n",
    "                        graph = create_graph_bi(plv_bi_matrix[:, :, epoch_n], selected_channels)\n",
    "                        graphs_bi.append(graph)\n",
    "                        epoch_n = epoch_n + 1\n",
    "                    \n",
    "                    # Save the results for the current file\n",
    "                    all_data[file_num] = {\n",
    "                        'eegICA': eegICA, \n",
    "                        'plv_bi': plv_bi, \n",
    "                        'graphs': graphs, \n",
    "                        'graphs_bi': graphs_bi}\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a file\n",
    "output_file = \"epgb_1t3760.pkl\" # save e(eg)p(lv)g(raph and)b(inary graph)\n",
    "with open(output_file, \"wb\") as f:\n",
    "    pickle.dump(all_data, f)\n",
    "\n",
    "print(f\"Data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegnetmibci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
